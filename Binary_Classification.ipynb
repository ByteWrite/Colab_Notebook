{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGXua-qoYy-h"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, SimpleRNN, Dense\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD07h9eHY4Y6"
      },
      "source": [
        "# get the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/tf2.0/sbux.csv')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLzNOpYuY6Pe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "5c908e79-d4fa-43d0-acd6-eb70a368fc2e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-02-08</td>\n",
              "      <td>27.920</td>\n",
              "      <td>28.325</td>\n",
              "      <td>27.920</td>\n",
              "      <td>28.185</td>\n",
              "      <td>7146296</td>\n",
              "      <td>SBUX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-02-11</td>\n",
              "      <td>28.260</td>\n",
              "      <td>28.260</td>\n",
              "      <td>27.930</td>\n",
              "      <td>28.070</td>\n",
              "      <td>5457354</td>\n",
              "      <td>SBUX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-02-12</td>\n",
              "      <td>28.000</td>\n",
              "      <td>28.275</td>\n",
              "      <td>27.975</td>\n",
              "      <td>28.130</td>\n",
              "      <td>8665592</td>\n",
              "      <td>SBUX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-02-13</td>\n",
              "      <td>28.230</td>\n",
              "      <td>28.230</td>\n",
              "      <td>27.750</td>\n",
              "      <td>27.915</td>\n",
              "      <td>7022056</td>\n",
              "      <td>SBUX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-02-14</td>\n",
              "      <td>27.765</td>\n",
              "      <td>27.905</td>\n",
              "      <td>27.675</td>\n",
              "      <td>27.775</td>\n",
              "      <td>8899188</td>\n",
              "      <td>SBUX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date    open    high     low   close   volume  Name\n",
              "0  2013-02-08  27.920  28.325  27.920  28.185  7146296  SBUX\n",
              "1  2013-02-11  28.260  28.260  27.930  28.070  5457354  SBUX\n",
              "2  2013-02-12  28.000  28.275  27.975  28.130  8665592  SBUX\n",
              "3  2013-02-13  28.230  28.230  27.750  27.915  7022056  SBUX\n",
              "4  2013-02-14  27.765  27.905  27.675  27.775  8899188  SBUX"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kLqFQ0-Y9Wr"
      },
      "source": [
        "# calculate returns by first shifting the data\n",
        "df['PrevClose'] = df['close'].shift(1) # move everything up 1\n",
        "\n",
        "# so now it's like\n",
        "# close / prev close\n",
        "# x[2] x[1]\n",
        "# x[3] x[2]\n",
        "# x[4] x[3]\n",
        "# ...\n",
        "# x[t] x[t-1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbVYCAdoY97B"
      },
      "source": [
        "# then the return is\n",
        "# (x[t] - x[t-1]) / x[t-1]\n",
        "df['Return'] = (df['close'] - df['PrevClose']) / df['PrevClose']"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GWGmHRvZAKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f0a454fd-6283-4c55-ee52-ce73c3b1c56b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>Name</th>\n",
              "      <th>PrevClose</th>\n",
              "      <th>Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-02-08</td>\n",
              "      <td>27.920</td>\n",
              "      <td>28.325</td>\n",
              "      <td>27.920</td>\n",
              "      <td>28.185</td>\n",
              "      <td>7146296</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-02-11</td>\n",
              "      <td>28.260</td>\n",
              "      <td>28.260</td>\n",
              "      <td>27.930</td>\n",
              "      <td>28.070</td>\n",
              "      <td>5457354</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>28.185</td>\n",
              "      <td>-0.004080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-02-12</td>\n",
              "      <td>28.000</td>\n",
              "      <td>28.275</td>\n",
              "      <td>27.975</td>\n",
              "      <td>28.130</td>\n",
              "      <td>8665592</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>28.070</td>\n",
              "      <td>0.002138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-02-13</td>\n",
              "      <td>28.230</td>\n",
              "      <td>28.230</td>\n",
              "      <td>27.750</td>\n",
              "      <td>27.915</td>\n",
              "      <td>7022056</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>28.130</td>\n",
              "      <td>-0.007643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-02-14</td>\n",
              "      <td>27.765</td>\n",
              "      <td>27.905</td>\n",
              "      <td>27.675</td>\n",
              "      <td>27.775</td>\n",
              "      <td>8899188</td>\n",
              "      <td>SBUX</td>\n",
              "      <td>27.915</td>\n",
              "      <td>-0.005015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date    open    high     low  ...   volume  Name PrevClose    Return\n",
              "0  2013-02-08  27.920  28.325  27.920  ...  7146296  SBUX       NaN       NaN\n",
              "1  2013-02-11  28.260  28.260  27.930  ...  5457354  SBUX    28.185 -0.004080\n",
              "2  2013-02-12  28.000  28.275  27.975  ...  8665592  SBUX    28.070  0.002138\n",
              "3  2013-02-13  28.230  28.230  27.750  ...  7022056  SBUX    28.130 -0.007643\n",
              "4  2013-02-14  27.765  27.905  27.675  ...  8899188  SBUX    27.915 -0.005015\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0na4SSfZDp2"
      },
      "source": [
        "# Now turn the full data into numpy arrays\n",
        "\n",
        "# Not yet in the final \"X\" format!\n",
        "input_data = df[['open', 'high', 'low', 'close', 'volume']].values\n",
        "targets = df['Return'].values"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0u9xJ5iZEwo"
      },
      "source": [
        "# Set Ntrain to two-thirds of the dataset\n",
        "N = len(input_data)\n",
        "Ntrain = N * 2 // 3"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pTXf4AxgKWy"
      },
      "source": [
        "# Set number of prev. time steps to use\n",
        "T = 10\n",
        "\n",
        "# Set input dimensionality\n",
        "D = input_data.shape[1]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rorls1Wf-I1"
      },
      "source": [
        "input_data_train = input_data[:Ntrain + T - 1]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTIBE4GagT2m"
      },
      "source": [
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(input_data_train)\n",
        "input_data = scaler.transform(input_data)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVGlcqI-gvLA"
      },
      "source": [
        "# Setup X_train and Y_train\n",
        "X_train = np.zeros((Ntrain, T, D))\n",
        "Y_train = np.zeros(Ntrain)\n",
        "\n",
        "for t in range(Ntrain):\n",
        "  X_train[t, :, :] = input_data[t:t+T]\n",
        "  Y_train[t] = (targets[t+T] > 0)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF7ThA3-Hu8X"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSgKVjZwHpAn",
        "outputId": "2d557007-3aaa-4143-f9b8-59833e7fe525"
      },
      "source": [
        "N - Ntrain"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf3-dNJ0g7V6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b49ca4-8bc1-4996-94a6-414c983f53b7"
      },
      "source": [
        "# Setup X_test and Y_test\n",
        "X_test = np.zeros((N - Ntrain, T, D))\n",
        "Y_test = np.zeros(N - Ntrain)\n",
        "print(len(targets))\n",
        "for u in range(N - Ntrain):\n",
        "  # u counts from 0...(N - Ntrain)\n",
        "  # t counts from Ntrain...N\n",
        "  t = u + Ntrain\n",
        "X_test[u, :, :] = input_data[t:t+T]\n",
        "Y_test[u] = (targets[t] > 0)\n",
        "#print(t+T)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rRm1SKlhXJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5459c38b-2c48-4d6b-961a-a4c407c6250a"
      },
      "source": [
        "# make the RNN\n",
        "i = Input(shape=(T, D))\n",
        "x = LSTM(50)(i)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(i, x)\n",
        "model.compile(\n",
        "  loss='binary_crossentropy',\n",
        "  optimizer=Adam(lr=0.001),\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HuaP9GRKKfQ",
        "outputId": "1d6b683a-c086-48c3-ba7c-9622b82e26b1"
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU16Cj_AhZls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08f82a7-0919-41d9-d9d6-31ef1b6b8462"
      },
      "source": [
        "# train the RNN\n",
        "r = model.fit(\n",
        "  X_train, Y_train,\n",
        "  batch_size=32,\n",
        "  epochs=300,\n",
        "  validation_data=(X_test, Y_test),\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "27/27 [==============================] - 35s 25ms/step - loss: 0.6940 - accuracy: 0.5089 - val_loss: 0.7294 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.5304 - val_loss: 0.7189 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6919 - accuracy: 0.5256 - val_loss: 0.7354 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.5161 - val_loss: 0.7348 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5221 - val_loss: 0.7438 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.5387 - val_loss: 0.7497 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5244 - val_loss: 0.7548 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6897 - accuracy: 0.5292 - val_loss: 0.7434 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.5471 - val_loss: 0.7625 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.5375 - val_loss: 0.7547 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6877 - accuracy: 0.5411 - val_loss: 0.7702 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6866 - accuracy: 0.5411 - val_loss: 0.7651 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.5280 - val_loss: 0.7698 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5352 - val_loss: 0.7702 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.5399 - val_loss: 0.7618 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6856 - accuracy: 0.5542 - val_loss: 0.7633 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.5435 - val_loss: 0.7691 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6854 - accuracy: 0.5530 - val_loss: 0.7668 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6858 - accuracy: 0.5518 - val_loss: 0.7629 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6857 - accuracy: 0.5423 - val_loss: 0.7595 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6845 - accuracy: 0.5590 - val_loss: 0.7647 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6854 - accuracy: 0.5566 - val_loss: 0.7605 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6852 - accuracy: 0.5554 - val_loss: 0.7642 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6836 - accuracy: 0.5614 - val_loss: 0.7709 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6865 - accuracy: 0.5471 - val_loss: 0.7685 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6852 - accuracy: 0.5542 - val_loss: 0.7666 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6836 - accuracy: 0.5602 - val_loss: 0.7655 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6850 - accuracy: 0.5614 - val_loss: 0.7559 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6825 - accuracy: 0.5650 - val_loss: 0.7556 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6857 - accuracy: 0.5518 - val_loss: 0.7583 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6857 - accuracy: 0.5554 - val_loss: 0.7577 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6832 - accuracy: 0.5662 - val_loss: 0.7549 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6808 - accuracy: 0.5709 - val_loss: 0.7635 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6813 - accuracy: 0.5638 - val_loss: 0.7601 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6805 - accuracy: 0.5864 - val_loss: 0.7566 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6819 - accuracy: 0.5542 - val_loss: 0.7539 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6823 - accuracy: 0.5566 - val_loss: 0.7550 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6792 - accuracy: 0.5638 - val_loss: 0.7523 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.5852 - val_loss: 0.7553 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6789 - accuracy: 0.5685 - val_loss: 0.7473 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6772 - accuracy: 0.5602 - val_loss: 0.7461 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6777 - accuracy: 0.5745 - val_loss: 0.7418 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6768 - accuracy: 0.5709 - val_loss: 0.7452 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6788 - accuracy: 0.5673 - val_loss: 0.7402 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.5578 - val_loss: 0.7411 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6761 - accuracy: 0.5685 - val_loss: 0.7395 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6757 - accuracy: 0.5626 - val_loss: 0.7491 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6736 - accuracy: 0.5697 - val_loss: 0.7456 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6739 - accuracy: 0.5745 - val_loss: 0.7483 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6737 - accuracy: 0.5757 - val_loss: 0.7470 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.5673 - val_loss: 0.7425 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.5816 - val_loss: 0.7326 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.5793 - val_loss: 0.7462 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6685 - accuracy: 0.5745 - val_loss: 0.7436 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.5816 - val_loss: 0.7413 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5662 - val_loss: 0.7479 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.5769 - val_loss: 0.7446 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.5888 - val_loss: 0.7488 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.5757 - val_loss: 0.7466 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6683 - accuracy: 0.5936 - val_loss: 0.7465 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6708 - accuracy: 0.5864 - val_loss: 0.7365 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6650 - accuracy: 0.5757 - val_loss: 0.7399 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.5769 - val_loss: 0.7411 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6623 - accuracy: 0.5816 - val_loss: 0.7455 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6639 - accuracy: 0.5888 - val_loss: 0.7475 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6629 - accuracy: 0.5888 - val_loss: 0.7416 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6628 - accuracy: 0.5912 - val_loss: 0.7297 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6613 - accuracy: 0.5900 - val_loss: 0.7434 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.5948 - val_loss: 0.7490 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6559 - accuracy: 0.6043 - val_loss: 0.7435 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6576 - accuracy: 0.6043 - val_loss: 0.7450 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6557 - accuracy: 0.6091 - val_loss: 0.7492 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6545 - accuracy: 0.5995 - val_loss: 0.7596 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6533 - accuracy: 0.6007 - val_loss: 0.7556 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6520 - accuracy: 0.6055 - val_loss: 0.7515 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6504 - accuracy: 0.6079 - val_loss: 0.7672 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6502 - accuracy: 0.6079 - val_loss: 0.7608 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6487 - accuracy: 0.6114 - val_loss: 0.7710 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6488 - accuracy: 0.6174 - val_loss: 0.7579 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6490 - accuracy: 0.6126 - val_loss: 0.7600 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.6174 - val_loss: 0.7824 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6446 - accuracy: 0.6079 - val_loss: 0.7648 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6418 - accuracy: 0.6162 - val_loss: 0.7569 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.6305 - val_loss: 0.7798 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6421 - accuracy: 0.6162 - val_loss: 0.7543 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6364 - accuracy: 0.6257 - val_loss: 0.7586 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6412 - accuracy: 0.6293 - val_loss: 0.7564 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6351 - accuracy: 0.6329 - val_loss: 0.7708 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6336 - accuracy: 0.6400 - val_loss: 0.7637 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6313 - accuracy: 0.6400 - val_loss: 0.7779 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6389 - val_loss: 0.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6361 - accuracy: 0.6198 - val_loss: 0.7844 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6312 - accuracy: 0.6305 - val_loss: 0.7609 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6355 - accuracy: 0.6353 - val_loss: 0.7727 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6286 - accuracy: 0.6508 - val_loss: 0.7675 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.6424 - val_loss: 0.7781 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6179 - accuracy: 0.6532 - val_loss: 0.7640 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6166 - accuracy: 0.6555 - val_loss: 0.7420 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6197 - accuracy: 0.6448 - val_loss: 0.7538 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6144 - accuracy: 0.6472 - val_loss: 0.7633 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/300\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.6115 - accuracy: 0.6496 - val_loss: 0.7510 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6112 - accuracy: 0.6460 - val_loss: 0.7764 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.6555 - val_loss: 0.7570 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6092 - accuracy: 0.6532 - val_loss: 0.7468 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.6544 - val_loss: 0.7813 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5997 - accuracy: 0.6579 - val_loss: 0.7572 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5997 - accuracy: 0.6615 - val_loss: 0.7333 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5961 - accuracy: 0.6710 - val_loss: 0.7329 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5927 - accuracy: 0.6841 - val_loss: 0.7307 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.6579 - val_loss: 0.7603 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5885 - accuracy: 0.6782 - val_loss: 0.7587 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5960 - accuracy: 0.6698 - val_loss: 0.7456 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5944 - accuracy: 0.6651 - val_loss: 0.7525 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5898 - accuracy: 0.6722 - val_loss: 0.7695 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5984 - accuracy: 0.6627 - val_loss: 0.7594 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5874 - accuracy: 0.6651 - val_loss: 0.7549 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5819 - accuracy: 0.6722 - val_loss: 0.7544 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5721 - accuracy: 0.6853 - val_loss: 0.7446 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.6841 - val_loss: 0.7610 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5727 - accuracy: 0.6698 - val_loss: 0.7595 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5678 - accuracy: 0.6830 - val_loss: 0.7518 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5681 - accuracy: 0.6889 - val_loss: 0.7489 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5664 - accuracy: 0.6782 - val_loss: 0.7536 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5628 - accuracy: 0.6841 - val_loss: 0.7397 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.6651 - val_loss: 0.7590 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5597 - accuracy: 0.6877 - val_loss: 0.7668 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5554 - accuracy: 0.7056 - val_loss: 0.7514 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5526 - accuracy: 0.7092 - val_loss: 0.7359 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5561 - accuracy: 0.6985 - val_loss: 0.7333 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5506 - accuracy: 0.7104 - val_loss: 0.7459 - val_accuracy: 0.0024\n",
            "Epoch 131/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5427 - accuracy: 0.7116 - val_loss: 0.7544 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5562 - accuracy: 0.6961 - val_loss: 0.7894 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.6985 - val_loss: 0.7685 - val_accuracy: 0.0024\n",
            "Epoch 134/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5391 - accuracy: 0.7032 - val_loss: 0.7762 - val_accuracy: 0.0024\n",
            "Epoch 135/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7116 - val_loss: 0.7659 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5330 - accuracy: 0.7080 - val_loss: 0.7627 - val_accuracy: 0.0024\n",
            "Epoch 137/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7187 - val_loss: 0.7827 - val_accuracy: 0.0024\n",
            "Epoch 138/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.7175 - val_loss: 0.7834 - val_accuracy: 0.0024\n",
            "Epoch 139/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5348 - accuracy: 0.7175 - val_loss: 0.8009 - val_accuracy: 0.0024\n",
            "Epoch 140/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5373 - accuracy: 0.7139 - val_loss: 0.7855 - val_accuracy: 0.0024\n",
            "Epoch 141/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.7187 - val_loss: 0.7649 - val_accuracy: 0.0024\n",
            "Epoch 142/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5467 - accuracy: 0.7008 - val_loss: 0.7678 - val_accuracy: 0.0024\n",
            "Epoch 143/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.7211 - val_loss: 0.7821 - val_accuracy: 0.0024\n",
            "Epoch 144/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5176 - accuracy: 0.7187 - val_loss: 0.7703 - val_accuracy: 0.0024\n",
            "Epoch 145/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7330 - val_loss: 0.7794 - val_accuracy: 0.0024\n",
            "Epoch 146/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7223 - val_loss: 0.7828 - val_accuracy: 0.0024\n",
            "Epoch 147/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7223 - val_loss: 0.7957 - val_accuracy: 0.0024\n",
            "Epoch 148/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5062 - accuracy: 0.7211 - val_loss: 0.7906 - val_accuracy: 0.0024\n",
            "Epoch 149/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5127 - accuracy: 0.7294 - val_loss: 0.7870 - val_accuracy: 0.0024\n",
            "Epoch 150/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5037 - accuracy: 0.7461 - val_loss: 0.8092 - val_accuracy: 0.0024\n",
            "Epoch 151/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.7426 - val_loss: 0.8429 - val_accuracy: 0.0024\n",
            "Epoch 152/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4975 - accuracy: 0.7366 - val_loss: 0.8120 - val_accuracy: 0.0024\n",
            "Epoch 153/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4964 - accuracy: 0.7437 - val_loss: 0.8571 - val_accuracy: 0.0024\n",
            "Epoch 154/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4995 - accuracy: 0.7354 - val_loss: 0.8447 - val_accuracy: 0.0024\n",
            "Epoch 155/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5016 - accuracy: 0.7354 - val_loss: 0.8157 - val_accuracy: 0.0024\n",
            "Epoch 156/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4895 - accuracy: 0.7569 - val_loss: 0.8261 - val_accuracy: 0.0024\n",
            "Epoch 157/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.7473 - val_loss: 0.8145 - val_accuracy: 0.0024\n",
            "Epoch 158/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4867 - accuracy: 0.7449 - val_loss: 0.8275 - val_accuracy: 0.0024\n",
            "Epoch 159/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.7521 - val_loss: 0.8034 - val_accuracy: 0.0024\n",
            "Epoch 160/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7664 - val_loss: 0.8266 - val_accuracy: 0.0024\n",
            "Epoch 161/300\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.4720 - accuracy: 0.7652 - val_loss: 0.8447 - val_accuracy: 0.0024\n",
            "Epoch 162/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.7640 - val_loss: 0.8409 - val_accuracy: 0.0024\n",
            "Epoch 163/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.7533 - val_loss: 0.8177 - val_accuracy: 0.0024\n",
            "Epoch 164/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.7533 - val_loss: 0.8665 - val_accuracy: 0.0024\n",
            "Epoch 165/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4685 - accuracy: 0.7759 - val_loss: 0.8915 - val_accuracy: 0.0024\n",
            "Epoch 166/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.7664 - val_loss: 0.8340 - val_accuracy: 0.0024\n",
            "Epoch 167/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.7700 - val_loss: 0.8773 - val_accuracy: 0.0024\n",
            "Epoch 168/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4589 - accuracy: 0.7723 - val_loss: 0.8268 - val_accuracy: 0.0024\n",
            "Epoch 169/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7831 - val_loss: 0.8400 - val_accuracy: 0.0024\n",
            "Epoch 170/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4588 - accuracy: 0.7819 - val_loss: 0.8315 - val_accuracy: 0.0024\n",
            "Epoch 171/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.7735 - val_loss: 0.8770 - val_accuracy: 0.0024\n",
            "Epoch 172/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.7747 - val_loss: 0.8864 - val_accuracy: 0.0024\n",
            "Epoch 173/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.7783 - val_loss: 0.8798 - val_accuracy: 0.0024\n",
            "Epoch 174/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7712 - val_loss: 0.8619 - val_accuracy: 0.0024\n",
            "Epoch 175/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.7878 - val_loss: 0.8893 - val_accuracy: 0.0024\n",
            "Epoch 176/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4459 - accuracy: 0.7831 - val_loss: 0.9115 - val_accuracy: 0.0024\n",
            "Epoch 177/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.7747 - val_loss: 0.9038 - val_accuracy: 0.0024\n",
            "Epoch 178/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.7843 - val_loss: 0.9149 - val_accuracy: 0.0024\n",
            "Epoch 179/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7938 - val_loss: 0.8806 - val_accuracy: 0.0024\n",
            "Epoch 180/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.7867 - val_loss: 0.9254 - val_accuracy: 0.0024\n",
            "Epoch 181/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.7962 - val_loss: 0.9098 - val_accuracy: 0.0024\n",
            "Epoch 182/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7938 - val_loss: 0.8868 - val_accuracy: 0.0024\n",
            "Epoch 183/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7890 - val_loss: 0.8874 - val_accuracy: 0.0024\n",
            "Epoch 184/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4192 - accuracy: 0.8045 - val_loss: 0.9502 - val_accuracy: 0.0024\n",
            "Epoch 185/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8045 - val_loss: 1.0310 - val_accuracy: 0.0024\n",
            "Epoch 186/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.7962 - val_loss: 1.0507 - val_accuracy: 0.0024\n",
            "Epoch 187/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4142 - accuracy: 0.8021 - val_loss: 1.0162 - val_accuracy: 0.0024\n",
            "Epoch 188/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8081 - val_loss: 1.0038 - val_accuracy: 0.0024\n",
            "Epoch 189/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 1.0143 - val_accuracy: 0.0024\n",
            "Epoch 190/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 1.0195 - val_accuracy: 0.0024\n",
            "Epoch 191/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.8010 - val_loss: 1.0557 - val_accuracy: 0.0024\n",
            "Epoch 192/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.8057 - val_loss: 1.0721 - val_accuracy: 0.0024\n",
            "Epoch 193/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8093 - val_loss: 0.9928 - val_accuracy: 0.0024\n",
            "Epoch 194/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4048 - accuracy: 0.8033 - val_loss: 1.1316 - val_accuracy: 0.0024\n",
            "Epoch 195/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8212 - val_loss: 1.0608 - val_accuracy: 0.0024\n",
            "Epoch 196/300\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.8081 - val_loss: 1.1365 - val_accuracy: 0.0024\n",
            "Epoch 197/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8153 - val_loss: 1.1059 - val_accuracy: 0.0024\n",
            "Epoch 198/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8200 - val_loss: 1.1270 - val_accuracy: 0.0024\n",
            "Epoch 199/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8212 - val_loss: 1.0267 - val_accuracy: 0.0024\n",
            "Epoch 200/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8129 - val_loss: 1.1355 - val_accuracy: 0.0024\n",
            "Epoch 201/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8331 - val_loss: 1.1274 - val_accuracy: 0.0024\n",
            "Epoch 202/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3724 - accuracy: 0.8272 - val_loss: 1.1555 - val_accuracy: 0.0024\n",
            "Epoch 203/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8212 - val_loss: 1.1462 - val_accuracy: 0.0024\n",
            "Epoch 204/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3703 - accuracy: 0.8391 - val_loss: 1.1716 - val_accuracy: 0.0024\n",
            "Epoch 205/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3662 - accuracy: 0.8296 - val_loss: 1.1347 - val_accuracy: 0.0024\n",
            "Epoch 206/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3693 - accuracy: 0.8355 - val_loss: 1.0962 - val_accuracy: 0.0024\n",
            "Epoch 207/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3658 - accuracy: 0.8248 - val_loss: 1.1628 - val_accuracy: 0.0024\n",
            "Epoch 208/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.3638 - accuracy: 0.8379 - val_loss: 1.1638 - val_accuracy: 0.0024\n",
            "Epoch 209/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.8391 - val_loss: 1.2062 - val_accuracy: 0.0024\n",
            "Epoch 210/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3563 - accuracy: 0.8319 - val_loss: 1.1472 - val_accuracy: 0.0024\n",
            "Epoch 211/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8367 - val_loss: 1.2405 - val_accuracy: 0.0024\n",
            "Epoch 212/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8427 - val_loss: 1.2303 - val_accuracy: 0.0024\n",
            "Epoch 213/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8343 - val_loss: 1.2008 - val_accuracy: 0.0024\n",
            "Epoch 214/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8379 - val_loss: 1.2339 - val_accuracy: 0.0024\n",
            "Epoch 215/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3449 - accuracy: 0.8486 - val_loss: 1.3198 - val_accuracy: 0.0024\n",
            "Epoch 216/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3460 - accuracy: 0.8331 - val_loss: 1.2355 - val_accuracy: 0.0024\n",
            "Epoch 217/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8498 - val_loss: 1.3670 - val_accuracy: 0.0024\n",
            "Epoch 218/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3319 - accuracy: 0.8605 - val_loss: 1.2833 - val_accuracy: 0.0024\n",
            "Epoch 219/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8284 - val_loss: 1.2921 - val_accuracy: 0.0024\n",
            "Epoch 220/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3380 - accuracy: 0.8474 - val_loss: 1.3249 - val_accuracy: 0.0024\n",
            "Epoch 221/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8558 - val_loss: 1.3817 - val_accuracy: 0.0024\n",
            "Epoch 222/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.8641 - val_loss: 1.3857 - val_accuracy: 0.0024\n",
            "Epoch 223/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8594 - val_loss: 1.3646 - val_accuracy: 0.0024\n",
            "Epoch 224/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.3256 - accuracy: 0.8498 - val_loss: 1.4216 - val_accuracy: 0.0024\n",
            "Epoch 225/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8474 - val_loss: 1.3997 - val_accuracy: 0.0024\n",
            "Epoch 226/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3235 - accuracy: 0.8582 - val_loss: 1.3973 - val_accuracy: 0.0024\n",
            "Epoch 227/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3172 - accuracy: 0.8594 - val_loss: 1.4284 - val_accuracy: 0.0024\n",
            "Epoch 228/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3177 - accuracy: 0.8522 - val_loss: 1.4091 - val_accuracy: 0.0024\n",
            "Epoch 229/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3143 - accuracy: 0.8617 - val_loss: 1.4439 - val_accuracy: 0.0024\n",
            "Epoch 230/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.3029 - accuracy: 0.8617 - val_loss: 1.4301 - val_accuracy: 0.0024\n",
            "Epoch 231/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3057 - accuracy: 0.8701 - val_loss: 1.4783 - val_accuracy: 0.0024\n",
            "Epoch 232/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3057 - accuracy: 0.8689 - val_loss: 1.4097 - val_accuracy: 0.0024\n",
            "Epoch 233/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3097 - accuracy: 0.8570 - val_loss: 1.5037 - val_accuracy: 0.0024\n",
            "Epoch 234/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8522 - val_loss: 1.5522 - val_accuracy: 0.0024\n",
            "Epoch 235/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3183 - accuracy: 0.8534 - val_loss: 1.5353 - val_accuracy: 0.0024\n",
            "Epoch 236/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.3127 - accuracy: 0.8510 - val_loss: 1.5720 - val_accuracy: 0.0024\n",
            "Epoch 237/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2932 - accuracy: 0.8737 - val_loss: 1.6372 - val_accuracy: 0.0024\n",
            "Epoch 238/300\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.2935 - accuracy: 0.8641 - val_loss: 1.6410 - val_accuracy: 0.0024\n",
            "Epoch 239/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2860 - accuracy: 0.8844 - val_loss: 1.6842 - val_accuracy: 0.0024\n",
            "Epoch 240/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2829 - accuracy: 0.8760 - val_loss: 1.7217 - val_accuracy: 0.0024\n",
            "Epoch 241/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2915 - accuracy: 0.8796 - val_loss: 1.6934 - val_accuracy: 0.0024\n",
            "Epoch 242/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2803 - accuracy: 0.8808 - val_loss: 1.7959 - val_accuracy: 0.0024\n",
            "Epoch 243/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2880 - accuracy: 0.8760 - val_loss: 1.7713 - val_accuracy: 0.0024\n",
            "Epoch 244/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2770 - accuracy: 0.8808 - val_loss: 1.8623 - val_accuracy: 0.0024\n",
            "Epoch 245/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2799 - accuracy: 0.8784 - val_loss: 1.8988 - val_accuracy: 0.0024\n",
            "Epoch 246/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2805 - accuracy: 0.8725 - val_loss: 1.8374 - val_accuracy: 0.0024\n",
            "Epoch 247/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2821 - accuracy: 0.8820 - val_loss: 1.8664 - val_accuracy: 0.0024\n",
            "Epoch 248/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2811 - accuracy: 0.8713 - val_loss: 2.0115 - val_accuracy: 0.0024\n",
            "Epoch 249/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2692 - accuracy: 0.8808 - val_loss: 2.0867 - val_accuracy: 0.0024\n",
            "Epoch 250/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2703 - accuracy: 0.8808 - val_loss: 1.8819 - val_accuracy: 0.0024\n",
            "Epoch 251/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2917 - accuracy: 0.8713 - val_loss: 2.0229 - val_accuracy: 0.0024\n",
            "Epoch 252/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2748 - accuracy: 0.8832 - val_loss: 2.1681 - val_accuracy: 0.0024\n",
            "Epoch 253/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2618 - accuracy: 0.8880 - val_loss: 2.1382 - val_accuracy: 0.0024\n",
            "Epoch 254/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2538 - accuracy: 0.8856 - val_loss: 2.2800 - val_accuracy: 0.0024\n",
            "Epoch 255/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2558 - accuracy: 0.8880 - val_loss: 2.1391 - val_accuracy: 0.0024\n",
            "Epoch 256/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2447 - accuracy: 0.8963 - val_loss: 2.3566 - val_accuracy: 0.0024\n",
            "Epoch 257/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2468 - accuracy: 0.9011 - val_loss: 2.2873 - val_accuracy: 0.0024\n",
            "Epoch 258/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2464 - accuracy: 0.8915 - val_loss: 2.3437 - val_accuracy: 0.0024\n",
            "Epoch 259/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.8963 - val_loss: 2.3307 - val_accuracy: 0.0024\n",
            "Epoch 260/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2476 - accuracy: 0.8951 - val_loss: 2.4149 - val_accuracy: 0.0024\n",
            "Epoch 261/300\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.2406 - accuracy: 0.9023 - val_loss: 2.4264 - val_accuracy: 0.0024\n",
            "Epoch 262/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2498 - accuracy: 0.8963 - val_loss: 2.5301 - val_accuracy: 0.0024\n",
            "Epoch 263/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2543 - accuracy: 0.8927 - val_loss: 2.4944 - val_accuracy: 0.0024\n",
            "Epoch 264/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2501 - accuracy: 0.8987 - val_loss: 2.5893 - val_accuracy: 0.0024\n",
            "Epoch 265/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2453 - accuracy: 0.8892 - val_loss: 2.6710 - val_accuracy: 0.0024\n",
            "Epoch 266/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2319 - accuracy: 0.8939 - val_loss: 2.8042 - val_accuracy: 0.0024\n",
            "Epoch 267/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.9070 - val_loss: 2.7171 - val_accuracy: 0.0024\n",
            "Epoch 268/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2270 - accuracy: 0.9130 - val_loss: 2.7298 - val_accuracy: 0.0024\n",
            "Epoch 269/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2307 - accuracy: 0.9046 - val_loss: 2.8341 - val_accuracy: 0.0024\n",
            "Epoch 270/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2255 - accuracy: 0.9094 - val_loss: 2.9329 - val_accuracy: 0.0024\n",
            "Epoch 271/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2230 - accuracy: 0.9070 - val_loss: 3.0926 - val_accuracy: 0.0024\n",
            "Epoch 272/300\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.2242 - accuracy: 0.9166 - val_loss: 3.0884 - val_accuracy: 0.0024\n",
            "Epoch 273/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2368 - accuracy: 0.9023 - val_loss: 3.2353 - val_accuracy: 0.0024\n",
            "Epoch 274/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2253 - accuracy: 0.9082 - val_loss: 3.0986 - val_accuracy: 0.0024\n",
            "Epoch 275/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2566 - accuracy: 0.8951 - val_loss: 3.2955 - val_accuracy: 0.0024\n",
            "Epoch 276/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.8939 - val_loss: 3.5403 - val_accuracy: 0.0024\n",
            "Epoch 277/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2361 - accuracy: 0.8975 - val_loss: 3.4070 - val_accuracy: 0.0024\n",
            "Epoch 278/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2332 - accuracy: 0.9058 - val_loss: 3.5364 - val_accuracy: 0.0024\n",
            "Epoch 279/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2190 - accuracy: 0.9130 - val_loss: 3.3408 - val_accuracy: 0.0024\n",
            "Epoch 280/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2323 - accuracy: 0.8915 - val_loss: 3.5060 - val_accuracy: 0.0024\n",
            "Epoch 281/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2264 - accuracy: 0.9035 - val_loss: 3.4824 - val_accuracy: 0.0024\n",
            "Epoch 282/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2378 - accuracy: 0.8951 - val_loss: 3.4526 - val_accuracy: 0.0024\n",
            "Epoch 283/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2397 - accuracy: 0.8987 - val_loss: 3.6836 - val_accuracy: 0.0024\n",
            "Epoch 284/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2221 - accuracy: 0.9094 - val_loss: 3.6876 - val_accuracy: 0.0024\n",
            "Epoch 285/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2140 - accuracy: 0.9154 - val_loss: 3.6667 - val_accuracy: 0.0024\n",
            "Epoch 286/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2023 - accuracy: 0.9154 - val_loss: 3.6682 - val_accuracy: 0.0024\n",
            "Epoch 287/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2062 - accuracy: 0.9118 - val_loss: 3.7045 - val_accuracy: 0.0024\n",
            "Epoch 288/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1991 - accuracy: 0.9190 - val_loss: 3.7270 - val_accuracy: 0.0024\n",
            "Epoch 289/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.9094 - val_loss: 3.7968 - val_accuracy: 0.0024\n",
            "Epoch 290/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2073 - accuracy: 0.9130 - val_loss: 3.8337 - val_accuracy: 0.0024\n",
            "Epoch 291/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2026 - accuracy: 0.9118 - val_loss: 3.8762 - val_accuracy: 0.0024\n",
            "Epoch 292/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2134 - accuracy: 0.9106 - val_loss: 3.9459 - val_accuracy: 0.0024\n",
            "Epoch 293/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1895 - accuracy: 0.9368 - val_loss: 3.8848 - val_accuracy: 0.0024\n",
            "Epoch 294/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1943 - accuracy: 0.9237 - val_loss: 3.9349 - val_accuracy: 0.0024\n",
            "Epoch 295/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.9058 - val_loss: 3.9863 - val_accuracy: 0.0024\n",
            "Epoch 296/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.2027 - accuracy: 0.9154 - val_loss: 4.0658 - val_accuracy: 0.0024\n",
            "Epoch 297/300\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.1896 - accuracy: 0.9309 - val_loss: 4.1109 - val_accuracy: 0.0024\n",
            "Epoch 298/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2163 - accuracy: 0.9190 - val_loss: 4.1735 - val_accuracy: 0.0024\n",
            "Epoch 299/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.2150 - accuracy: 0.9058 - val_loss: 4.1914 - val_accuracy: 0.0024\n",
            "Epoch 300/300\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.1875 - accuracy: 0.9273 - val_loss: 4.2623 - val_accuracy: 0.0024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbNHKB4jhdpq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "63fa8ab1-381a-49b0-cd1a-9fda0ccff980"
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1d348c93JpPJnpAQEkiAAIKsghYRqqB1l6LUulu1+ljtz9aq3Z7a2lpr26e7ts+jrY+PWhWXQtVarCutKGIFCfuOYU9YspB9m+38/jiDhJCEAZLcmcn3/XrN696598693zuTfOfMueeeI8YYlFJKxT6X0wEopZTqHprQlVIqTmhCV0qpOKEJXSml4oQmdKWUihMJTh24f//+pqioyKnDK6VUTFq+fHmlMSa3o3WOJfSioiKKi4udOrxSSsUkEdnZ2TqtclFKqTihCV0ppeKEJnSllIoTjtWhd8Tv91NaWkpLS4vToUS1pKQkCgsL8Xg8ToeilIoiUZXQS0tLSU9Pp6ioCBFxOpyoZIyhqqqK0tJShg0b5nQ4SqkoElVVLi0tLeTk5Ggy74KIkJOTo79ilFJHiKqEDmgyj4C+R0qpjkRdQldKqbj23q9g+6Ie2bUm9HbS0tKcDkEpFa8aKuC9X8CuJT2ye03oSinVW0oWAAZGXdQju9eE3gljDN/97ncZP348EyZMYO7cuQDs3buXGTNmMGnSJMaPH88HH3xAMBjk5ptv/nTbhx9+2OHolVJRactbkD4Q8k/pkd1HVbPFtn7y2no27Knr1n2OHZTBjy8dF9G2r7zyCqtWrWL16tVUVlZy+umnM2PGDF544QUuuugi7rvvPoLBIE1NTaxatYqysjLWrVsHQE1NTbfGrZSKA9s/gC3vwClXQw81bNASeicWL17Mddddh9vtJi8vj7PPPptly5Zx+umn8+c//5kHHniAtWvXkp6ezvDhw9m2bRvf+MY3eOutt8jIyHA6fKVUNGmphReuhqwhcPZ/9thhoraEHmlJurfNmDGDRYsW8frrr3PzzTfzrW99i5tuuonVq1fz9ttv89hjjzFv3jyeeuopp0NVSkWLzW+Cvwm+8EfILOyxw2gJvRPTp09n7ty5BINBKioqWLRoEVOmTGHnzp3k5eVx22238ZWvfIUVK1ZQWVlJKBTiiiuu4Gc/+xkrVqxwOnylVDRZ/zfIHAwFn+nRw0RtCd1pl19+OR999BETJ05ERPj1r39Nfn4+zzzzDL/5zW/weDykpaXx7LPPUlZWxi233EIoFALgF7/4hcPRK6WiRkM5lPwLzvhqj9WdHyTGmB49QGcmT55s2g9wsXHjRsaMGeNIPLFG3yulYsQ/fwKLH4ZvLIecESe8OxFZboyZ3NE6rXJRSqme4m+BZU/C2Mu6JZkfTcQJXUTcIrJSRP7RwTqviMwVkRIRWSoiRd0ZpFJKxaTdS6G1FiZe3yuHO5YS+t3Axk7W3QpUG2NOAh4GfnWigSmlVMzb9h64EqDozF45XEQJXUQKgc8DT3SyyWzgmfD8S8B5ol0CKqX6uu3vQ8Fk8Kb3yuEiLaH/HvhPINTJ+gJgN4AxJgDUAjntNxKR20WkWESKKyoqjiNcpZSKEQ3lsGclDD+71w551IQuIrOAcmPM8hM9mDHmcWPMZGPM5Nzc3BPdnVJKRZ/majAGVjwDJgQTruq1Q0dSQj8TuExEdgB/Ac4VkefabVMGDAYQkQQgE6jqxjiVUir61ZbCb0+GVS9A8dMw/BzoP7LXDn/UhG6M+b4xptAYUwRcC7xrjLmh3WbzgS+H568Mb+NMA/de1FXf6Tt27GD8+PG9GI1SynGb34RgK7z9A6grhdO/0quHP+47RUXkQaDYGDMfeBKYIyIlwAFs4ldKqb5l85t22lID6YNg1CW9evhjSujGmPeA98Lz97dZ3gJ0b0XRm/fCvrXdukvyJ8Alv+x09b333svgwYP5+te/DsADDzxAQkICCxcupLq6Gr/fz89+9jNmz559TIdtaWnhjjvuoLi4mISEBB566CE+97nPsX79em655RZ8Ph+hUIiXX36ZQYMGcfXVV1NaWkowGORHP/oR11xzzQmdtlKqF7TUwo4PYORF8Mk7MPk/wN27vatoXy5tXHPNNdxzzz2fJvR58+bx9ttvc9ddd5GRkUFlZSVTp07lsssuO6aBmh999FFEhLVr17Jp0yYuvPBCtmzZwmOPPcbdd9/Nl770JXw+H8FgkDfeeINBgwbx+uuvA1BbW9sj56qU6mYf/x8EffC5H8C598GAsb0eQvQm9C5K0j3l1FNPpby8nD179lBRUUG/fv3Iz8/nm9/8JosWLcLlclFWVsb+/fvJz8+PeL+LFy/mG9/4BgCjR49m6NChbNmyhWnTpvHzn/+c0tJSvvjFLzJy5EgmTJjAt7/9bb73ve8xa9Yspk+f3lOnq5TqLi118NEjtnQ+aJJjYWhfLu1cddVVvPTSS8ydO5drrrmG559/noqKCpYvX86qVavIy8ujpaWlW451/fXXM3/+fJKTk5k5cybvvvsuo0aNYsWKFUyYMIEf/vCHPPjgg91yLKVUD1r8kG2ueM69joYRvSV0h1xzzTXcdtttVFZW8v777zNv3jwGDBiAx+Nh4cKF7Ny585j3OX36dJ5//nnOPfdctmzZwq5duzj55JPZtm0bw4cP56677mLXrl2sWbOG0aNHk52dzQ033EBWVhZPPNHZzblKqahQvw8++iNMvA4KTnM0FE3o7YwbN476+noKCgoYOHAgX/rSl7j00kuZMGECkydPZvTo0ce8z6997WvccccdTJgwgYSEBJ5++mm8Xi/z5s1jzpw5eDwe8vPz+cEPfsCyZcv47ne/i8vlwuPx8Kc//akHzlIp1W02vW6bKp55t9ORaH/osUrfK6WixPNXQeUWuGtVjw9gAdofulJK9YzWetj2vm1vHgX9EWqVywlau3YtN95442HLvF4vS5cudSgipVSvCPrhr7fYporjr3A6GiAKE7ox5pjaeDttwoQJrFq1qleP2Qd6VVAq+gRaofgpqNsD0+6EdS9DyQKY9TAMPt3p6IAoS+hJSUlUVVWRk5MTU0m9NxljqKqqIikpyelQlOpbti+Ct8LNEjfOh6YDMOJc+MwtzsbVRlQl9MLCQkpLS9G+0ruWlJREYWGh02Eo1bfU77XTL/4fLP495A6Amb+Nirrzg6IqoXs8HoYNG+Z0GEopdaSGcjsdcxmccrWzsXRCW7kopVQkGsrBmwGe6K3u1ISulFKRaCyH1OgeaU0TulJKRaKhAtLynI6iS5GMKZokIh+LyGoRWS8iP+lgm5tFpEJEVoUfvTtMh1JKdYeWOlj/KoRCUL7x8HWN5ZAW+yX0VuBcY8xEYBJwsYhM7WC7ucaYSeGH9iillIo9a+fBX78MH/wW/jgNanYfWtewH1IHOBdbBCIZU9QYYxrCTz3hh97ZopSKP/X77XTNXMBAyT/huSugYrMdkSgtxhM6gIi4RWQVUA4sMMZ0dF/7FSKyRkReEpHBnezndhEpFpFibWuulIo6jeG8VFVipyufs0n90Sn2eTwkdGNM0BgzCSgEpohI++HsXwOKjDGnAAuAZzrZz+PGmMnGmMm5udFdF6WU6oMa2xU09605/HmsV7m0ZYypARYCF7dbXmWMaQ0/fQL4TPeEp5RSvaix8vDnQR9kj7ADPgNkdVj5EDUiaeWSKyJZ4flk4AJgU7ttBrZ5ehnQ7vKwUkrFgPYldICsIfD5h+BrSyB/Qu/HdAwiufV/IPCMiLixXwDzjDH/EJEHgWJjzHzgLhG5DAgAB4CbeypgpZTqMY2VkJAEgRbIKIS6Uug31PbXMiD6B5Q5akI3xqwBTu1g+f1t5r8PfL97Q1NKqV4UaIXWWjjzHlsS37bQXhTNGuJ0ZBHTO0WVUgoO1Z9nD4MJV0L6IPs8a6hzMR0jTehKKQWH6s8P9teSEU7o/YocCed4RFX3uUop5ZiDJfSDCf3kS6BiE+Sf4lxMx0gTulJKQZsSen87Tc+HS37lXDzHQatclFIKbF8tEPU3D3VFE7pSSoEd/NmbAd40pyM5blrlopTq2yo2w5p5UFcG6QOPvn0U04SulOrbVr8Iix+2g1fEwM1DXdEqF6VU33Zgm5027IeMAmdjOUGa0JVSfVvVtkPzMV7logldKdV3GXOohA6QoQldKaViU8N+8Dceen7wdv8YpQldKdV3VW2107Q8O9USulJKxaBdS+HpmXZ+VHjMnoxC5+LpBtpsUSnVN63/m50OOg3OfwBGz4K02B4aM5IRi5JE5GMRWS0i60XkJx1s4xWRuSJSIiJLRaSoJ4JVSqluU70D8sbD7QshJRtGXeh0RCcskiqXVuBcY8xEYBJwsYhMbbfNrUC1MeYk4GEgtnq0UUr1PdU7Yqqv80gcNaEbqyH81BN+mHabzQaeCc+/BJwnItJtUSqlVHcyBmp2xlRf55GI6KKoiLhFZBVQDiwwxixtt0kBsBvAGBMAaoGcDvZzu4gUi0hxRUUHg7EqpVRvaKwAf5MdLzSORJTQjTFBY8wkoBCYIiLjj+dgxpjHjTGTjTGTc3Nj++KDUiqGVe+w075YQj/IGFMDLAQubreqDBgMICIJQCZQ1R0BKqVUt6veaad9LaGLSK6IZIXnk4ELgE3tNpsPfDk8fyXwrjGmfT27UkpFh4O3+2cNcTaObhZJO/SBwDMi4sZ+AcwzxvxDRB4Eio0x84EngTkiUgIcAK7tsYiVUupE7VsD2SPAk+x0JN3qqAndGLMGOLWD5fe3mW8Brure0JRSqoeUrYCiM52Ootvprf9Kqb6lfh/U77F3iMYZTehKqb6lbIWdFmhCV0qp2LZnBYgb8k9xOpJupwldKRX/trwDC35s58tW2LFDE1OcjakHaEJXSsW/lXPgw99DYxXsWQmDJjkdUY/QhK6Uin+VW+x0zVxoPhCXF0RBE7pSKt4FA4dGJvroUTuNwwuioAldKRXvanZCyG/n60rBkwoDxjkbUw/RhK6Uim8Vm+30tC/bli3XPg8Jic7G1EN0CDqlVHw7WH9+wYOQnOVsLD1MS+hKqfi2fx2kD4z7ZA6a0JVS8cwY2LEYhkxzOpJeoQldKRW/qkqgfi8Mm+F0JL1CE7pSKn5tf99ONaErpVSM2/EhpA+C7OFOR9IrNKErpeJX6TIYPAVEnI6kV0QyBN1gEVkoIhtEZL2I3N3BNueISK2IrAo/7u9oX0op1SvKN8Gav0LtbpvQ+4hI2qEHgG8bY1aISDqwXEQWGGM2tNvuA2PMrO4PUSmljtGcy+0gFgCFpzsbSy86agndGLPXGLMiPF8PbAQKejowpZQ6LsYcSuYAAyc6F0svO6Y6dBEpwo4vurSD1dNEZLWIvCkiHXaUICK3i0ixiBRXVFQcc7BKKXVUtaV2OvgMOOf7kOB1Np5eFPGt/yKSBrwM3GOMqWu3egUw1BjTICIzgVeBke33YYx5HHgcYPLkyea4o1ZKqc7sWWmnF/0CCj/jbCy9LKISuoh4sMn8eWPMK+3XG2PqjDEN4fk3AI+I9O/WSJVSKhK7l4IrAfLis0fFrkTSykWAJ4GNxpiHOtkmP7wdIjIlvN+q7gxUKaWOatFv4aNHoOgs8CQ5HU2vi6TK5UzgRmCtiKwKL/sBMATAGPMYcCVwh4gEgGbgWmOMVqkopXrXimegaDpc+6LTkTjiqAndGLMY6LJVvjHmEeCR7gpKKaUiZoy9cahml31MuzMuB4COhPaHrpSKXXMuh+YauPwxWPJHu2zomc7G5CBN6Eqp2LX1XTt94Rqo3m7nB4x1Lh6HaUJXSsW+6u0wehaMuhhcfbeLKk3oSqnYU70DQsFDzxOS4Qt/gqQMx0KKBprQlVKx5683g7/ZzueNhwlX9flkDprQlVKxJhSyvSkGwgn9/J/AyPOdjSlK9N3KJqVUbKrfcyiZA6TnORdLlNGErpSKLVUlhz9P04R+kCZ0pVRsaZvQxQ0pOc7FEmW0Dl0pFTteuxuWPw1uLwRbITUXXG6no4oamtCVUrHBGJvMwSbz9IGQNsDRkKKNJnSlVGxoatOB6xl3QKAFvGnOxROFNKErpWLDwbrz6+fBqIucjSVKaUJXSkW3Jy6AMZdCSrZ9nnOSs/FEMW3lopSKXjW7ofRjWPAjqNpqRyLKGup0VFErkhGLBovIQhHZICLrReTuDrYREflvESkRkTUiclrPhKuU6lO2/stOE5JtlUu/InBrxUJnInlnAsC3jTErRCQdWC4iC4wxG9pscwl2UOiRwBnAn8JTpZQ6fiXhhJ6UCQe2QfYIZ+OJckctoRtj9hpjVoTn64GNQEG7zWYDzxprCZAlIgO7PVqlVN+y80M7bSy3VS5af96lY6pDF5Ei4FRgabtVBcDuNs9LOTLpIyK3i0ixiBRXVFQcW6RKqb6ludo2Vew3DEzI9t+SM9zpqKJaxAldRNKAl4F7jDF1x3MwY8zjxpjJxpjJubm5x7MLpVRfUbXNTovOOrRMS+hdiiihi4gHm8yfN8a80sEmZcDgNs8Lw8uUUur4HGx33jahax16lyJp5SLAk8BGY8xDnWw2H7gp3NplKlBrjNnbjXEqpfqaA1sBgSFT7fOEJMg4oiZXtRFJK5czgRuBtSKyKrzsB8AQAGPMY8AbwEygBGgCbun+UJVScS8YgJdvhXGX24ugmYPtQ9yQPbxPjxcaiaMmdGPMYkCOso0Bvt5dQSml+qjlf4YNr0LNLsDYi6AuN2QM0vrzCGgLfaVUdAgF4b1f2qqVPSvA5YHTv2LXXfGE7SpXdUl/vyilosP+9dBUCWd/zz5PyoCz7rHzQ6ZCjl4QPRotoSulosPu8O0t468ATzIMOhXS852NKcZoQldKOSsUgr9cD1vetINWZA2BqXc4HVVM0ioXpZSzDmyzyRzshU/psg2G6oImdKWUs/assNN+RfDZuxwNJdZplYtSyjk1u6G02HaPe+dy7Rr3BOm7p5Ryxv718L8zIBSAwWdoMu8GWuWilHLGOz+ybc/B3g2qTph+JSqlet+OD+1oRBf8FEJ+GHOZ0xHFBU3oSqneVbcHFv6XvfNzym22zbnqFprQlVK9p7YMHp0Cvga4+FeazLuZJnSlVO/Z+JpN5je+CiM+53Q0cUcviiqles/G12DAWE3mPUQTulKq5xkD1Tth179hzKVORxO3Ihmx6CkRKReRdZ2sP0dEakVkVfhxf/eHqZSKWQe2w29HwbOzwe2F025yOqK4FUkd+tPAI8CzXWzzgTFmVrdEpJSKL0v/FxrLoRE4+17ILHQ6orgVyYhFi0SkqOdDUUrFndYGWPkcTLgKzvom5I5xOqK41l2tXKaJyGpgD/AdY8z6jjYSkduB2wGGDBnSTYdWSkWdUBDW/82OPuSrh1NvgLxxTkcV97ojoa8AhhpjGkRkJvAqMLKjDY0xjwOPA0yePNl0w7GVUtFo7V/hb1+FzCF2gOfC052OqE844VYuxpg6Y0xDeP4NwCMi/U84MqVUbDHG9p74ly/B+7+yy2p32ZJ5YqqzsfURJ1xCF5F8YL8xxojIFOyXRNUJR6aUim51e2Dx72HGd2DfGnjldkjLg/INdn36QKjfC4OnOBtnH3LUhC4iLwLnAP1FpBT4MeABMMY8BlwJ3CEiAaAZuNYYo9UpSsW7jx6Fj/8Xti2EllporoGmKvjcfTDoNHC5Yc4XYMg0pyPtMyJp5XLdUdY/gm3WqJSKdxVbbN14Sy00H4AB4yDQYvs0/4+3oLkaRpxn+zY3Bm76OxRNdzrqPkP7clFKdW7tS7DgfrizGBJTYPFDULkFUrJt8r7sfzq/81MEhp/Tm9H2eXrrv1Kqczs+gLoy2L3UtinfMB/GfxFueQsu+Q2MusTpCFUbWkJXSh1p1xLb9LBis32+YzFUlYC/ESZeD5kFcMbtzsaojqAJXSl1pGVP2ITuSjj03BhbHz5kqrOxqU5plYtS6nDG2CHiwF7sTMqElho7P+v3tm5cRSUtoSulDle9A+r3HHp+8S/B3wSjZ0F6vmNhqaPThK6UglUv2GqVs75pmyQC5E2A/Wth6JnQb6iz8amIaEJXqi9rbYDWOpvQy5bD3BttKbxfEVz8X7D8acgc7HSUKkKa0JXqy/72Vdsk0d8Mk75k56tK4IaXYdgM+1AxQxO6Un3F9kW2RD56JgT9sO092PSPQ+uHfw7O/k/YswpOOt+xMNXx04SuVLxb9FvYvw42vQEYe9fn+7+GVc/ZFizitrfxDz7dVrX0K3I4YHW8NKErFetWvQBZQ2HDq5Caa1ujJKbaASa2vw9b37VJO7MQGsrhnR/Ctvdh5IUw87dQ/KRN9ll64TPWiVMdI06ePNkUFxc7cmyl4oYx8MuhNllXbrZtxQFyR0PDftvfyuCpcP1ccHtsd7eLfm23ue4vcPIlEAqBCdr1KuqJyHJjzOSO1umNRUrFssYKaK2F8vU2maeEx5ap2GST+QU/hVvegOQsW2o/8y5IHQCelEMdZ7lcmszjhFa5KBWLWupg4c9tYj4oMQ3uWQMb/g6v3mGXDZpk+yU/yJsOV/3Zlt49yb0bs+pxkQxw8RQwCyg3xozvYL0AfwBmAk3AzcaYFd0dqFJ9Ums9vPszGH+lvWgJEPDBn2fam34O8mbA8LNtKbygza/x/AlH7rPorJ6NWTkmkiqXp4GLu1h/CXZQ6JHA7cCfTjwspRShEDx3JSx9DF75im0rbgwsedQm8+zhdju3F766CC79b/s85ySb4LOGQHI/5+JXvS6SEYsWiUhRF5vMBp4NDzu3RESyRGSgMWZvN8WoVN+0fx3sXgITrrI9Hz53hR3Hs3q7baFyxv+D574IOSMge9ih17lccMrVtnpF9SndUYdeAOxu87w0vEwTulInYvv7dnrBg3Zcznd/Cv2GwWe/YRO2uMGdaBN6e5//Xe/GqqJCr14UFZHbsdUyDBkypDcPrVTs2b4IckZCxiA4/Vb7aO+yR6D/Sb0fm4pK3dFssQxo23tPYXjZEYwxjxtjJhtjJufm5nbDoZWKUwEf7Pz30ftSmXgNFHymd2JSUa87Evp84CaxpgK1Wn+u1DHwNdoE/t4vbT8qYPtZ8TXAyAscDU3FlkiaLb4InAP0F5FS4MeAB8AY8xjwBrbJYgm22eItPRWsUnFj57/hla/asTl3LbGdYZUsgA9+B1c8AVveti1VRpzrdKQqhkTSyuW6o6w3wNe7LSKlYtXK5+CjR+Gmv0P9Xhg40S43Blb/BTa/AYPPsO3An7/adozVVGUHjyhZAAPG2XbkL3/FXvAc9wVI8Dp7Tiqm6J2iSnWm6YC9o3LAmKNvu3sZvHa3vf3+2dlQvgFuXQCDp8DqF+2dm6m5sHE+iMveon/rO7aEXr4J5lwO5//Ybv/Gf9oxPKd+refPUcUV7ZxLqfa2f2DH1dzwd1ty/swtMOvhIwdHLvmn7elw0Gm2ieGelTZRV2y060ddbDu/+uhR27zwqx/AptfgXw/awZaHTT+0L2N08GUVka4659ISulJtNVTA3BtsCRnsrfPL/wy1pbbvk/R8qNwCJ8+Et+619dzrXrbbnv09e2fmW/faqpUtb9kHwOWP2xt+xs62j/Y0matuoAldxYfOSrjGQPFTti33yZd0/NoD22zCzhsP8++0rU76FUFjJXz5NfjbHfDJO/bOy5Za29nVtvdg2Nlw7Qu2O9qVz8Hk/7Al9CHTbOL/8A8w5jJo2AdjOkjiSnWz+K5yCbTan7qt9XY+tb/9pw8G7D9lRwmguQZCQVvScsVZ78L+Fvt+ALz/S3vTyilXwdqXbMIb+lm7LhiwdcFly6F2t61KcHtg+ndsybW21A5lNuqiw9/Dhgpbdzz8bFsvvOHvMP1bXXfNGvSfeNetzdXwf+fZ7mBPvsT2cZI1xHZqdbAqBGDanXDe/fDhf9vPNqW/Tcwb5x/qRxzsoA/jLrcJfcBo26SwpdaW0Fvr7PuyYT7MeujQ7fXBALi1fKR6XldVLvGT0GtLoXyjHaF80a/tT+GVc8CTavuLBtvpvzfdtvX1pEDOcMgeATW7ICnDdklaVgwmdOjC1dDP2gTVXG0TYko27F0DTZW2E6Sck2zydyfaLwlPMhRNP7zL0oOMgaDPbhsKdJ7IDpY2fY2QkNTxvto7+OUlArVl9twTUyF9oB3UwOWy70//UZBRAJ+8bV9XNB12fGDfjzPvtl9mK+fY8w20hHcugLH7D/oOHXP0LFu3vOxJqCuFshU2oZ/1LVui3b8OJt0Asx+xcdXsgo/+aN+v026EZU/Y5Dr2MpuMU/rb29iX/AlcCbYNdu5oqN9nL0x+8DtbhTHucpjxXfu+hILwj2/CimcOxSUuyCiE2l22fnv8Fbb/k2VP2PP0Nx3aNn2QPc7oWbBvtf17GP/Fo7/fSjkkvhJ6KGjrMLOG2BJgbSmsmQdVnxzaxuWBkN/+k6b2t0nenWiTjDEw8BSbmKpKoGobZAy0ydObDkPPhLQBduCAur2w8bVDXwgHJabbn+QHth6eHA5yJ9pEmpJtS3c5I2xCq9pme8k7mFS8mbZVQ/Zwe5zUHJvI9q2zXzBNVXZ/yf1sEgsF7MW66p229cXASTDhSnv+pctsKVtctlR9MAkDZA6x55g9AnZ+aEubU++w70HxU1B4OuxfD3XhG3wHjLVfZGn5MOpC27xu+TNQsdkmXk+S/SWz4Ef2eCYECcl2fyPOtRcSIdy2+p+2ZHzyTHjnPntuJmhfA/ZOyD2rD3+PE5JtsvY1HL4s0AyDTrUl7qFn2WZ9Hz1i35Mz7rDdy3pSbQl672oYMwtOu8m+3hj4+HF7DifPtJ9NKGDPXeuvVQyJr4S+Zh68chuk5dmkBvafe/RMOybi5jds50UZBTZBn+g/q7/FDqCblGkTcWOlLfkmptjuTevKbOLxN9skVVsKe1bYpNtS2ybBYl9/0vk2mSf3s22VN78F9Xtg1CX29b4G2365td72oBf029FnNr4Gydm2zXLWUPtF9ckC+6WSOdgm9prd9gsh92RbKk1MtQksf4L9guhIKGTfo9Y6+2WZmHqopH80K561Y1OeebetM67fZ78sdyy29dKn3givfg1Wv3DoNUMUuysAABGRSURBVFfPsV9gG1617bGHnW3Pu2aXLUVvfgvO+Ko9px0f2OVuj/0VMPVrtopo1Yvwxnfse5U7Bs65F8ZcGtkvGaViXFwl9LI9ZVT96w8Mq3qfXZO+Q8uAibjScklOdFPV4CPJ4yYz2UN6UgJu1+FJSYD0JA/+YAiXCB634HYJ4mQJLdBqvyQyC7reLhQ6sk4/6IetC2HotOjtKtUY2LfGtulOzrIl7O7ga7JdyfYbqsOnqT4lrpotLtsP96w/Gzgb3gL4JPw4cSI26YsIArjCCzKTPbT4gtS3Bkj3JjAoK5lUr5tAyOAPGoKhEN4EN3kZXlK9CQRCBq/bhdfjIhQCfyhEbroXtwjeBDdZKR6MMQQNeNzCgHQv3r3lDMjw2mr2kCEl0c2A9CT21bUQMoa6Zj/jCjJJ87b5yNweWyUSzUQO3THZnRJTtJdBpdqJuYQ+65SBnDE8m/K6VnzBEL5AiBZ/kCZfkP5pXloDQepaAtQ1+2n/6yNkoK7ZjyfBhTHgC4QIGWNrmsNTY8BgwlMIGUN1oy35Z6UkUtfsp6ymmWZfkAS3kOBy4XELTb4gpdXNNPuDuF2CLxCiNWDriRNcQlWjD2PsF8CJcLuEnNREfMEQqYkJZCZ7yEqxj+zURFr9IbweF5nJnk8f6UkeUr0JpHntr5aQMQzLSSUrxePsrxOlVLeKuYSe4HYxMDOZgZmxOcCtLxCivsWPSwSXS2gNBKmob6XFH6KivgWX2GqghtYA++taGJiZjNslJHvcrN9TS5MvSGVDK94EN02+ILXNPmqa/GzeV8+BRh/eBPenX2rBUOdfHiL2F0iaN4GxAzNo8gXwJrhBINnjZuLgLHLTvRRmJbOjqpHqJj8piW5cApeMH8jg7JRO962UckbM1aGryBhjaGgNUNvsp6E1QGNrgPqWwKe/QDbsqQt/IfhZXVpDsseNLxBCRKhr8bO9spG2fxousb9wDjppQBoDM5Nwu4RgyDCxMIuCfskke9wkeVykehMoyknVxK9UN4urOnQVGREhPclWt3Tk3NF5Xb4+EAxR1ehj14EmMpI8FPZLxh8MUd8SYP7qPazaXUN5fSv+cLXVH98roaMfBEOyU8hITmBEbho5qV5qmnyMK8hk4946MpM99EvxsLasltmTCjh39ACSPNpSRanjpSV01S18gRCVDa20+IO0+G210tqyWlbuqqG+NcDW8gYqGlpJSXRT0+QnJzWRRl+AFn+IrBQPNU1+kj1uZk8axIB0LyLCqLx0+qV6SPa4yctIYltFI+MLMshKSXT6dJVyjJbQVY9LTHAxKOvw6xpnDM857LkxhkDIUFrdTFFOCsGQ4UCTj+yURBZ9UsEba/fxyooyfMFQp8dJ8riYUJDJiNw0apv9jMxL57Mjcnhr3T4KspK5+vTBZCZ33oyxvK6FxASXfimouBRRCV1ELgb+ALiBJ4wxv2y3/mbgNxwaS/QRY8wTXe1TS+iqI6GQsb0eBEN8sr+B+hZb/19W00xBVjKLSypZV1bLtspG0pMS2H2giZCxLYkCIYMn3PJoVH46nxnSj2Z/kKqGVqoafWSnJrL4k0ryMrz8/c6zukz8SkWrE7qxSETcwBbgAqAUWAZcZ4zZ0Gabm4HJxpg7Iw1KE7rqDpUNrXy0tYpJg7OoafLzxrq9tPiDLNl2gF1VjSR53PRP85KdmsiOqkYGZ6ewclc1yeHlAAMyvEwfmYtLBIPh3NEDyM9I+rQUHwiGMIDHHWedtamYdKJVLlOAEmPMtvDO/gLMBjZ0+SqlekH/NC+XThwEwOBsmFCYedTXfPBJBW+u2xdu9WPYVtHIb97e/On6X7+1GREY3C+FkDHsrW0hzZvArWcNY1ReOi6BnLREThvSDxGhvL6FvTUtnFKYqe36laMiSegFwO42z0uBMzrY7goRmYEtzX/TGLO7/QYicjtwO8CQIUOOPVqlusH0kblMH5l72LLKhlZCIUOjL8jaslq2VzSytaIBl0BhvxRWl9bw0IIth71meG4q2SmJLN9VjTHw2RE5TBueQ1pSAlOGZTNyQDqJCVqqV72nuy6Kvga8aIxpFZGvAs8ARwxXbox5HHgcbJVLNx1bqRN2sPoFYFj/1A63qWpoZW+t7VJ4w546Xluzh5omP3edO5LkRDdzPtrJv7dWHfG6ZI+bC8fl0eQLsr+uhcJ+yZw/Jo/EBBcn56Vz0oA0LdmrbhFJHfo04AFjzEXh598HMMb8opPt3cABY0yXv321Dl3FoxZ/kAONPj7efoCdVU0EjaGsupl3N+0nN91LXkYSn+xvYF9dy6evGZ2fzsTCLLZWNFDd5KPFH8IfDPEfZw3jhqlD8bhtH0BKwYlfFE3AVqOch23Fsgy43hizvs02A40xe8PzlwPfM8ZM7Wq/mtBVXxUM2Tt1XS5YsauG+avKKClvYHhuGnkZXpI9Ceyva2FxSeWnrxmUmcTYQRls3l9PMGjIy0wiPyOJQVnJDO6XzPRRuYzITaO8rgVvgpvMFG3BE69O6KKoMSYgIncCb2ObLT5ljFkvIg8CxcaY+cBdInIZEAAOADd3W/RKxRm3Sz69eDtuUCY3Th16xDbGGN5Yu489Nc20+INsKW9g/Z5aRg5IJyvFQ3ldK5+UN/De5gqa/UFcAtmpXiobWhGBcYMymDEyl1MKMzk5P4NUrxsMDMhI6u3TVb1I7xRVKoaZcCucOUt2Ut3o46QBaTS2BvlwayXLd1YTDLfrd4sg4Y7V+qV4aPGHGJKTwthBGXx2RA4NLQFcIvRL1Ruuol1cDXChlIpMTZOP0upm3lm/D1/QUN/i550N+2nxBfF6XFQ2+A7bPtHtYtqIHHyBEMNyU8lLTyLJ4+L8sXlU1rfy6qo93DRtKKPz0/UiroM0oSuljtDkC/BhSRUb9tSRlpTAln31LN9VTXpSAtsrG6lp8n+6rQif9r5ZkJXM9WcM4eS8dOYW7+bj7Qe4dspgZk8sIM2bwMCspMNuwiqva+E3b29mxqhcLhqXr005T5AmdKXUMQsEQ1Q2+Hhz3V7217Vy3ZTBvL+lgnfW7//0gm12aiKnFGby3uaKT1/nTXBx5WcKSfK4afYHeW9TOXvCzT3TvAn8+NKxXDV5sCPnFA80oSulutXuA02UlDcwbUQOSR43ZTXNFO84QGsgxJJtVby6sgxvgu0b/6QBaXx/5hiqGnw8uXgbS7YdwJvgYsqwbEbnp1O8s5rxgzLxBUKMK8hgSHYKTb4g/mCIYMgweWg2/dMT+ebcVfRP8/KjWWP7dDfLmtCVUr2qNRAk0e06oq69NRDk2X/vpKymmUWfVLCjspGRA9IpqWgg0e2i2R88Yl8et9A/zcv+uhZCBkblpfH9S8YwZmAGWSmeTpN7MGQIhMf7jdTOqkYykjxRfXFYu89VSvWqzpKoN8HNbTOGf/o8FDK4XEJtk58Ur5s1pbWEjCEjyUOCWwgEDS9+vIv9dS1cfmoBHreLH766jlueXgbYKp8zhmXT6AsSDNkSfX5GEv6Q4b1N5bQGQowZmME5J+fy/84eQar3yJTnC4SobvLx3JKd/M+7JXjcwn9dPoFZpwwiOdGeRyAYYun2AzT7gpxzci4JUdpRm5bQlVIxpTUQZOGmcirqW3l3Uzk7DzSRnuQhwSW4BErKGwiGDJdOHERGsoeVu6pZsu0Aad4EivqnEAgaGn0BTinIIjs1kQ9LKtlW2YgIXDwunwONPpZut9VCnzt5AP/eWklyopv9da0ATB/Zn/s+P4bR+RmfxuQPhkhwCSJ2nGBvgpuaJh+3PL2ML08r4gunFrCvtoXqJt8JtxLSKhelVJ8RDBmMMYeVopfvPMCrK/ewu7oJlwiJbhcb99VR2+ynICuZacNz2FrRwB+uO5VEt4uFm8p5ZWUZ/9y4nwvH5uEPGq44rZADja389PWN+AIhpo/sjzfBRb+URP62soy8jCRG5aXxwSeV3HXeSCobWnn2o514E1z8YOYYfv76RnzBEF88tYDfXT3xuJO6JnSllDpGxhjqmgNHdKNQ3ehjzpKdvPjxLpI9brZVNvL5CQMJGcPaslqyUjysK6sDYNYpA1m1u4bS6maGZKdw3pgB/PnDHfzsC+O5oYM7hCOhdehKKXWMRKTDPnH6pSZy13kjueu8kYCtg2/btt4XCDFnyU5SE91cfloB/qDhhaU7OX9MHkU5qVQ2+MhN9x6x326JWUvoSikVO7oqoUfnpVqllFLHTBO6UkrFCU3oSikVJzShK6VUnIgooYvIxSKyWURKROTeDtZ7RWRueP1SESnq7kCVUkp17agJPTxG6KPAJcBY4DoRGdtus1uBamPMScDDwK+6O1CllFJdi6SEPgUoMcZsM8b4gL8As9ttMxt4Jjz/EnCeaA/4SinVqyJJ6AXA7jbPS8PLOtzGGBMAaoGc9jsSkdtFpFhEiisqKtqvVkopdQJ69U5RY8zjwOMAIlIhIjuPc1f9gcqjbhUb9Fyik55LdNJzgU77DIgkoZcBbYcXKQwv62ibUhFJADKBqq52aozJjeDYHRKR4s7ulIo1ei7RSc8lOum5dC2SKpdlwEgRGSYiicC1wPx228wHvhyevxJ41zjVp4BSSvVRRy2hG2MCInIn8DbgBp4yxqwXkQeBYmPMfOBJYI6IlAAHsElfKaVUL4qoDt0Y8wbwRrtl97eZbwGu6t7QuvR4Lx6rp+m5RCc9l+ik59IFx3pbVEop1b301n+llIoTmtCVUipOxFxCP1q/MtFORHaIyFoRWSUixeFl2SKyQEQ+CU/7OR1nR0TkKREpF5F1bZZ1GLtY/x3+nNaIyGnORX6kTs7lAREpC382q0RkZpt13w+fy2YRuciZqI8kIoNFZKGIbBCR9SJyd3h5zH0uXZxLLH4uSSLysYisDp/LT8LLh4X7uyoJ93+VGF7ePf1hGWNi5oFtZbMVGA4kAquBsU7HdYznsAPo327Zr4F7w/P3Ar9yOs5OYp8BnAasO1rswEzgTUCAqcBSp+OP4FweAL7TwbZjw39rXmBY+G/Q7fQ5hGMbCJwWnk8HtoTjjbnPpYtzicXPRYC08LwHWBp+v+cB14aXPwbcEZ7/GvBYeP5aYO7xHDfWSuiR9CsTi9r2hfMM8AUHY+mUMWYRtllqW53FPht41lhLgCwRGdg7kR5dJ+fSmdnAX4wxrcaY7UAJ9m/RccaYvcaYFeH5emAjtiuOmPtcujiXzkTz52KMMQ3hp57wwwDnYvu7giM/lxPuDyvWEnok/cpEOwO8IyLLReT28LI8Y8ze8Pw+IM+Z0I5LZ7HH6md1Z7gq4qk2VV8xcS7hn+mnYkuDMf25tDsXiMHPRUTcIrIKKAcWYH9B1Bjb3xUcHm9E/WEdTawl9HhwljHmNGx3xF8XkRltVxr7mysm25LGcuxhfwJGAJOAvcDvnA0nciKSBrwM3GOMqWu7LtY+lw7OJSY/F2NM0BgzCdtdyhRgdE8fM9YSeiT9ykQ1Y0xZeFoO/A37Qe8/+LM3PC13LsJj1lnsMfdZGWP2h/8JQ8D/cejne1Sfi4h4sAnweWPMK+HFMfm5dHQusfq5HGSMqQEWAtOwVVwHb+hsG++n5yIR9ofVkVhL6JH0KxO1RCRVRNIPzgMXAus4vC+cLwN/dybC49JZ7POBm8KtKqYCtW2qAKJSu7rky7GfDdhzuTbcEmEYMBL4uLfj60i4nvVJYKMx5qE2q2Luc+nsXGL0c8kVkazwfDJwAfaawEJsf1dw5Ody4v1hOX01+DiuHs/EXv3eCtzndDzHGPtw7FX51cD6g/Fj68r+BXwC/BPIdjrWTuJ/EfuT14+t/7u1s9ixV/kfDX9Oa4HJTscfwbnMCce6JvwPNrDN9veFz2UzcInT8beJ6yxsdcoaYFX4MTMWP5cuziUWP5dTgJXhmNcB94eXD8d+6ZQAfwW84eVJ4ecl4fXDj+e4euu/UkrFiVirclFKKdUJTehKKRUnNKErpVSc0ISulFJxQhO6UkrFCU3oSikVJzShK6VUnPj/nR3UIBCfjTQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUfeFhNBLGkN",
        "outputId": "f83b23ff-7704-4447-afb7-f251bcaa3215"
      },
      "source": [
        "#r.history"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.5089392066001892,\n",
              "  0.5303933024406433,\n",
              "  0.5256257653236389,\n",
              "  0.5160905718803406,\n",
              "  0.5220500826835632,\n",
              "  0.5387365818023682,\n",
              "  0.5244338512420654,\n",
              "  0.5292014479637146,\n",
              "  0.547079861164093,\n",
              "  0.5375446677207947,\n",
              "  0.5411204099655151,\n",
              "  0.5411204099655151,\n",
              "  0.5280095338821411,\n",
              "  0.5351608991622925,\n",
              "  0.5399284958839417,\n",
              "  0.5542312264442444,\n",
              "  0.5435041785240173,\n",
              "  0.5530393123626709,\n",
              "  0.5518474578857422,\n",
              "  0.5423122644424438,\n",
              "  0.5589988231658936,\n",
              "  0.5566149950027466,\n",
              "  0.5554231405258179,\n",
              "  0.5613825917243958,\n",
              "  0.547079861164093,\n",
              "  0.5542312264442444,\n",
              "  0.5601906776428223,\n",
              "  0.5613825917243958,\n",
              "  0.5649582743644714,\n",
              "  0.5518474578857422,\n",
              "  0.5554231405258179,\n",
              "  0.5661501884460449,\n",
              "  0.5709177851676941,\n",
              "  0.563766360282898,\n",
              "  0.5864123702049255,\n",
              "  0.5542312264442444,\n",
              "  0.5566149950027466,\n",
              "  0.563766360282898,\n",
              "  0.5852205157279968,\n",
              "  0.5685339570045471,\n",
              "  0.5601906776428223,\n",
              "  0.5744934678077698,\n",
              "  0.5709177851676941,\n",
              "  0.5673421025276184,\n",
              "  0.5578069090843201,\n",
              "  0.5685339570045471,\n",
              "  0.5625745058059692,\n",
              "  0.5697258710861206,\n",
              "  0.5744934678077698,\n",
              "  0.5756853222846985,\n",
              "  0.5673421025276184,\n",
              "  0.5816448330879211,\n",
              "  0.5792610049247742,\n",
              "  0.5744934678077698,\n",
              "  0.5816448330879211,\n",
              "  0.5661501884460449,\n",
              "  0.576877236366272,\n",
              "  0.5887961983680725,\n",
              "  0.5756853222846985,\n",
              "  0.5935637950897217,\n",
              "  0.5864123702049255,\n",
              "  0.5756853222846985,\n",
              "  0.576877236366272,\n",
              "  0.5816448330879211,\n",
              "  0.5887961983680725,\n",
              "  0.5887961983680725,\n",
              "  0.5911799669265747,\n",
              "  0.5899880528450012,\n",
              "  0.5947556495666504,\n",
              "  0.6042908430099487,\n",
              "  0.6042908430099487,\n",
              "  0.6090583801269531,\n",
              "  0.5995232462882996,\n",
              "  0.600715160369873,\n",
              "  0.6054826974868774,\n",
              "  0.6078665256500244,\n",
              "  0.6078665256500244,\n",
              "  0.6114422082901001,\n",
              "  0.617401659488678,\n",
              "  0.6126340627670288,\n",
              "  0.617401659488678,\n",
              "  0.6078665256500244,\n",
              "  0.6162097454071045,\n",
              "  0.630512535572052,\n",
              "  0.6162097454071045,\n",
              "  0.6257449388504028,\n",
              "  0.6293206214904785,\n",
              "  0.6328963041305542,\n",
              "  0.6400476694107056,\n",
              "  0.6400476694107056,\n",
              "  0.6388557553291321,\n",
              "  0.619785487651825,\n",
              "  0.630512535572052,\n",
              "  0.6352800726890564,\n",
              "  0.6507747173309326,\n",
              "  0.6424314379692078,\n",
              "  0.6531585454940796,\n",
              "  0.6555423140525818,\n",
              "  0.6448152661323547,\n",
              "  0.6471990346908569,\n",
              "  0.6495828628540039,\n",
              "  0.6460071802139282,\n",
              "  0.6555423140525818,\n",
              "  0.6531585454940796,\n",
              "  0.6543503999710083,\n",
              "  0.657926082611084,\n",
              "  0.6615017652511597,\n",
              "  0.671036958694458,\n",
              "  0.6841477751731873,\n",
              "  0.657926082611084,\n",
              "  0.6781883239746094,\n",
              "  0.6698450446128845,\n",
              "  0.6650774478912354,\n",
              "  0.6722288727760315,\n",
              "  0.6626936793327332,\n",
              "  0.6650774478912354,\n",
              "  0.6722288727760315,\n",
              "  0.6853396892547607,\n",
              "  0.6841477751731873,\n",
              "  0.6698450446128845,\n",
              "  0.6829559206962585,\n",
              "  0.6889153718948364,\n",
              "  0.6781883239746094,\n",
              "  0.6841477751731873,\n",
              "  0.6650774478912354,\n",
              "  0.6877234578132629,\n",
              "  0.7056019306182861,\n",
              "  0.7091776132583618,\n",
              "  0.6984505653381348,\n",
              "  0.7103694677352905,\n",
              "  0.711561381816864,\n",
              "  0.6960667371749878,\n",
              "  0.6984505653381348,\n",
              "  0.7032181024551392,\n",
              "  0.711561381816864,\n",
              "  0.7079856991767883,\n",
              "  0.7187127470970154,\n",
              "  0.7175208330154419,\n",
              "  0.7175208330154419,\n",
              "  0.7139451503753662,\n",
              "  0.7187127470970154,\n",
              "  0.700834333896637,\n",
              "  0.7210965156555176,\n",
              "  0.7187127470970154,\n",
              "  0.7330154776573181,\n",
              "  0.7222884297370911,\n",
              "  0.7222884297370911,\n",
              "  0.7210965156555176,\n",
              "  0.7294397950172424,\n",
              "  0.7461263537406921,\n",
              "  0.7425506711006165,\n",
              "  0.7365911602973938,\n",
              "  0.7437425255775452,\n",
              "  0.7353993058204651,\n",
              "  0.7353993058204651,\n",
              "  0.7568534016609192,\n",
              "  0.7473182082176208,\n",
              "  0.7449344396591187,\n",
              "  0.75208580493927,\n",
              "  0.7663885354995728,\n",
              "  0.765196681022644,\n",
              "  0.7640047669410706,\n",
              "  0.7532777190208435,\n",
              "  0.7532777190208435,\n",
              "  0.7759237289428711,\n",
              "  0.7663885354995728,\n",
              "  0.7699642181396484,\n",
              "  0.7723480463027954,\n",
              "  0.7830750942230225,\n",
              "  0.781883180141449,\n",
              "  0.7735399007797241,\n",
              "  0.7747318148612976,\n",
              "  0.7783074975013733,\n",
              "  0.7711561322212219,\n",
              "  0.7878426909446716,\n",
              "  0.7830750942230225,\n",
              "  0.7747318148612976,\n",
              "  0.784267008304596,\n",
              "  0.7938021421432495,\n",
              "  0.7866507768630981,\n",
              "  0.7961859107017517,\n",
              "  0.7938021421432495,\n",
              "  0.7890345454216003,\n",
              "  0.8045291900634766,\n",
              "  0.8045291900634766,\n",
              "  0.7961859107017517,\n",
              "  0.8021454215049744,\n",
              "  0.8081048727035522,\n",
              "  0.7985697388648987,\n",
              "  0.7985697388648987,\n",
              "  0.8009535074234009,\n",
              "  0.80572110414505,\n",
              "  0.8092967867851257,\n",
              "  0.8033373355865479,\n",
              "  0.8212157487869263,\n",
              "  0.8081048727035522,\n",
              "  0.8152562379837036,\n",
              "  0.8200238347053528,\n",
              "  0.8212157487869263,\n",
              "  0.8128724694252014,\n",
              "  0.8331347107887268,\n",
              "  0.8271751999855042,\n",
              "  0.8212157487869263,\n",
              "  0.8390941619873047,\n",
              "  0.8295590281486511,\n",
              "  0.835518479347229,\n",
              "  0.824791431427002,\n",
              "  0.8379022479057312,\n",
              "  0.8390941619873047,\n",
              "  0.8319427967071533,\n",
              "  0.8367103934288025,\n",
              "  0.8426698446273804,\n",
              "  0.8343265652656555,\n",
              "  0.8379022479057312,\n",
              "  0.8486292958259583,\n",
              "  0.8331347107887268,\n",
              "  0.8498212099075317,\n",
              "  0.8605482578277588,\n",
              "  0.8283671140670776,\n",
              "  0.8474374413490295,\n",
              "  0.8557807207107544,\n",
              "  0.8641239404678345,\n",
              "  0.8593564033508301,\n",
              "  0.8498212099075317,\n",
              "  0.8474374413490295,\n",
              "  0.8581644892692566,\n",
              "  0.8593564033508301,\n",
              "  0.8522049784660339,\n",
              "  0.8617401719093323,\n",
              "  0.8617401719093323,\n",
              "  0.8700834512710571,\n",
              "  0.8688915371894836,\n",
              "  0.8569725751876831,\n",
              "  0.8522049784660339,\n",
              "  0.8533968925476074,\n",
              "  0.8510131239891052,\n",
              "  0.8736591339111328,\n",
              "  0.8641239404678345,\n",
              "  0.8843861818313599,\n",
              "  0.876042902469635,\n",
              "  0.8796185851097107,\n",
              "  0.8808104991912842,\n",
              "  0.876042902469635,\n",
              "  0.8808104991912842,\n",
              "  0.8784266710281372,\n",
              "  0.8724672198295593,\n",
              "  0.8820024132728577,\n",
              "  0.8712753057479858,\n",
              "  0.8808104991912842,\n",
              "  0.8808104991912842,\n",
              "  0.8712753057479858,\n",
              "  0.8831942677497864,\n",
              "  0.8879618644714355,\n",
              "  0.8855780959129333,\n",
              "  0.8879618644714355,\n",
              "  0.8963051438331604,\n",
              "  0.9010726809501648,\n",
              "  0.8915375471115112,\n",
              "  0.8963051438331604,\n",
              "  0.8951132297515869,\n",
              "  0.9022645950317383,\n",
              "  0.8963051438331604,\n",
              "  0.8927294611930847,\n",
              "  0.8986889123916626,\n",
              "  0.889153778553009,\n",
              "  0.8939213156700134,\n",
              "  0.9070321917533875,\n",
              "  0.9129916429519653,\n",
              "  0.9046483635902405,\n",
              "  0.9094159603118896,\n",
              "  0.9070321917533875,\n",
              "  0.916567325592041,\n",
              "  0.9022645950317383,\n",
              "  0.9082241058349609,\n",
              "  0.8951132297515869,\n",
              "  0.8939213156700134,\n",
              "  0.8974969983100891,\n",
              "  0.905840277671814,\n",
              "  0.9129916429519653,\n",
              "  0.8915375471115112,\n",
              "  0.9034565091133118,\n",
              "  0.8951132297515869,\n",
              "  0.8986889123916626,\n",
              "  0.9094159603118896,\n",
              "  0.9153754711151123,\n",
              "  0.9153754711151123,\n",
              "  0.9117997884750366,\n",
              "  0.918951153755188,\n",
              "  0.9094159603118896,\n",
              "  0.9129916429519653,\n",
              "  0.9117997884750366,\n",
              "  0.9106078743934631,\n",
              "  0.9368295669555664,\n",
              "  0.9237186908721924,\n",
              "  0.905840277671814,\n",
              "  0.9153754711151123,\n",
              "  0.9308700561523438,\n",
              "  0.918951153755188,\n",
              "  0.905840277671814,\n",
              "  0.9272943735122681],\n",
              " 'loss': [0.6940145492553711,\n",
              "  0.6916371583938599,\n",
              "  0.69189453125,\n",
              "  0.6916144490242004,\n",
              "  0.690125048160553,\n",
              "  0.6885672211647034,\n",
              "  0.6914451122283936,\n",
              "  0.6897135376930237,\n",
              "  0.6886065602302551,\n",
              "  0.687436580657959,\n",
              "  0.6877042651176453,\n",
              "  0.6866284012794495,\n",
              "  0.6876260638237,\n",
              "  0.6869937777519226,\n",
              "  0.6874224543571472,\n",
              "  0.685647189617157,\n",
              "  0.6868595480918884,\n",
              "  0.6854467988014221,\n",
              "  0.6857582330703735,\n",
              "  0.6856836676597595,\n",
              "  0.684538722038269,\n",
              "  0.685391902923584,\n",
              "  0.6852002143859863,\n",
              "  0.6836099624633789,\n",
              "  0.6864986419677734,\n",
              "  0.6851515769958496,\n",
              "  0.6835654377937317,\n",
              "  0.6849690675735474,\n",
              "  0.682489275932312,\n",
              "  0.6856650710105896,\n",
              "  0.6856515407562256,\n",
              "  0.683173418045044,\n",
              "  0.6807882189750671,\n",
              "  0.6813293099403381,\n",
              "  0.6804723143577576,\n",
              "  0.681922972202301,\n",
              "  0.6823363304138184,\n",
              "  0.6791900396347046,\n",
              "  0.6779658794403076,\n",
              "  0.6788521409034729,\n",
              "  0.6772101521492004,\n",
              "  0.6777001619338989,\n",
              "  0.6768434643745422,\n",
              "  0.6788173913955688,\n",
              "  0.6760603785514832,\n",
              "  0.6761282086372375,\n",
              "  0.6757156252861023,\n",
              "  0.673589825630188,\n",
              "  0.6739425659179688,\n",
              "  0.6737307906150818,\n",
              "  0.6742190718650818,\n",
              "  0.6714027523994446,\n",
              "  0.6715376973152161,\n",
              "  0.6685388684272766,\n",
              "  0.66954505443573,\n",
              "  0.6694306135177612,\n",
              "  0.6688176393508911,\n",
              "  0.6653022766113281,\n",
              "  0.6689549088478088,\n",
              "  0.6683170199394226,\n",
              "  0.6707838773727417,\n",
              "  0.6650345325469971,\n",
              "  0.6649712324142456,\n",
              "  0.6622741222381592,\n",
              "  0.6638632416725159,\n",
              "  0.662897527217865,\n",
              "  0.6627781391143799,\n",
              "  0.6613020300865173,\n",
              "  0.6579814553260803,\n",
              "  0.6559187173843384,\n",
              "  0.6575707197189331,\n",
              "  0.6556565761566162,\n",
              "  0.654474675655365,\n",
              "  0.6533027291297913,\n",
              "  0.6519774198532104,\n",
              "  0.6503552198410034,\n",
              "  0.6501679420471191,\n",
              "  0.6486511826515198,\n",
              "  0.6487945318222046,\n",
              "  0.6489987969398499,\n",
              "  0.6432256698608398,\n",
              "  0.6445546746253967,\n",
              "  0.641829252243042,\n",
              "  0.6363715529441833,\n",
              "  0.6421267986297607,\n",
              "  0.6364439725875854,\n",
              "  0.6412462592124939,\n",
              "  0.6350684762001038,\n",
              "  0.6335856318473816,\n",
              "  0.631252110004425,\n",
              "  0.627726137638092,\n",
              "  0.6361322402954102,\n",
              "  0.6311583518981934,\n",
              "  0.6354679465293884,\n",
              "  0.6286306381225586,\n",
              "  0.6209036111831665,\n",
              "  0.6178678274154663,\n",
              "  0.6165682077407837,\n",
              "  0.6196658611297607,\n",
              "  0.6143519282341003,\n",
              "  0.611450731754303,\n",
              "  0.6112233400344849,\n",
              "  0.6100107431411743,\n",
              "  0.6092018485069275,\n",
              "  0.6070014238357544,\n",
              "  0.5997394323348999,\n",
              "  0.5997245907783508,\n",
              "  0.5960853695869446,\n",
              "  0.5926601886749268,\n",
              "  0.5970435738563538,\n",
              "  0.588474452495575,\n",
              "  0.596046507358551,\n",
              "  0.5943681597709656,\n",
              "  0.5898141264915466,\n",
              "  0.5983863472938538,\n",
              "  0.5873971581459045,\n",
              "  0.5819202661514282,\n",
              "  0.5720833539962769,\n",
              "  0.5734541416168213,\n",
              "  0.5726576447486877,\n",
              "  0.5677843689918518,\n",
              "  0.5681347846984863,\n",
              "  0.5664358735084534,\n",
              "  0.562764585018158,\n",
              "  0.568801999092102,\n",
              "  0.5597275495529175,\n",
              "  0.5554252862930298,\n",
              "  0.5526328086853027,\n",
              "  0.5561236143112183,\n",
              "  0.5505582094192505,\n",
              "  0.5427491068840027,\n",
              "  0.5561591386795044,\n",
              "  0.5461854338645935,\n",
              "  0.539142906665802,\n",
              "  0.5412583351135254,\n",
              "  0.5330057740211487,\n",
              "  0.5317416191101074,\n",
              "  0.5332016348838806,\n",
              "  0.5347610712051392,\n",
              "  0.5373477935791016,\n",
              "  0.5311097502708435,\n",
              "  0.5467233061790466,\n",
              "  0.5206521153450012,\n",
              "  0.5175759196281433,\n",
              "  0.5185900330543518,\n",
              "  0.5176773071289062,\n",
              "  0.511804461479187,\n",
              "  0.506201446056366,\n",
              "  0.5127217769622803,\n",
              "  0.5037348866462708,\n",
              "  0.5030797123908997,\n",
              "  0.4975074231624603,\n",
              "  0.49643614888191223,\n",
              "  0.4994930326938629,\n",
              "  0.5016427636146545,\n",
              "  0.48947492241859436,\n",
              "  0.48587360978126526,\n",
              "  0.48667702078819275,\n",
              "  0.4859415888786316,\n",
              "  0.4763038158416748,\n",
              "  0.4720340669155121,\n",
              "  0.4786233603954315,\n",
              "  0.48611530661582947,\n",
              "  0.47269532084465027,\n",
              "  0.46845269203186035,\n",
              "  0.46857765316963196,\n",
              "  0.46245262026786804,\n",
              "  0.4589427411556244,\n",
              "  0.45848244428634644,\n",
              "  0.45881080627441406,\n",
              "  0.44931653141975403,\n",
              "  0.45177045464515686,\n",
              "  0.4551970064640045,\n",
              "  0.4520162045955658,\n",
              "  0.44359272718429565,\n",
              "  0.44585120677948,\n",
              "  0.4409753680229187,\n",
              "  0.4325520098209381,\n",
              "  0.42878198623657227,\n",
              "  0.43412595987319946,\n",
              "  0.43519267439842224,\n",
              "  0.4367451071739197,\n",
              "  0.4367790222167969,\n",
              "  0.4191652536392212,\n",
              "  0.4193059504032135,\n",
              "  0.41813552379608154,\n",
              "  0.4141722321510315,\n",
              "  0.40943190455436707,\n",
              "  0.41663527488708496,\n",
              "  0.41504091024398804,\n",
              "  0.4127715229988098,\n",
              "  0.4101281762123108,\n",
              "  0.40633663535118103,\n",
              "  0.4047544300556183,\n",
              "  0.3935364782810211,\n",
              "  0.39600440859794617,\n",
              "  0.40082743763923645,\n",
              "  0.3963490426540375,\n",
              "  0.38992634415626526,\n",
              "  0.38322439789772034,\n",
              "  0.3827192485332489,\n",
              "  0.3724157214164734,\n",
              "  0.38181793689727783,\n",
              "  0.3703494071960449,\n",
              "  0.36620572209358215,\n",
              "  0.36934664845466614,\n",
              "  0.36582109332084656,\n",
              "  0.36381059885025024,\n",
              "  0.3558797240257263,\n",
              "  0.35629549622535706,\n",
              "  0.35932546854019165,\n",
              "  0.3477118909358978,\n",
              "  0.35142821073532104,\n",
              "  0.34873899817466736,\n",
              "  0.34487977623939514,\n",
              "  0.34600040316581726,\n",
              "  0.3399687707424164,\n",
              "  0.3318883776664734,\n",
              "  0.3493514358997345,\n",
              "  0.337995707988739,\n",
              "  0.33337849378585815,\n",
              "  0.32371020317077637,\n",
              "  0.3175434172153473,\n",
              "  0.32558542490005493,\n",
              "  0.33572912216186523,\n",
              "  0.3235407769680023,\n",
              "  0.31721559166908264,\n",
              "  0.3177318572998047,\n",
              "  0.31431418657302856,\n",
              "  0.30289435386657715,\n",
              "  0.3057498037815094,\n",
              "  0.3056943118572235,\n",
              "  0.3096548020839691,\n",
              "  0.3292013704776764,\n",
              "  0.31831246614456177,\n",
              "  0.31267982721328735,\n",
              "  0.2932238280773163,\n",
              "  0.29353293776512146,\n",
              "  0.2859915494918823,\n",
              "  0.2829289138317108,\n",
              "  0.2915244996547699,\n",
              "  0.280347615480423,\n",
              "  0.2879902124404907,\n",
              "  0.27697762846946716,\n",
              "  0.2799054682254791,\n",
              "  0.28045597672462463,\n",
              "  0.28214195370674133,\n",
              "  0.2810605466365814,\n",
              "  0.26922062039375305,\n",
              "  0.27028584480285645,\n",
              "  0.2917349934577942,\n",
              "  0.2748386859893799,\n",
              "  0.26181676983833313,\n",
              "  0.25381579995155334,\n",
              "  0.25582176446914673,\n",
              "  0.24471831321716309,\n",
              "  0.24684859812259674,\n",
              "  0.24639450013637543,\n",
              "  0.24584759771823883,\n",
              "  0.24761813879013062,\n",
              "  0.24063549935817719,\n",
              "  0.24978986382484436,\n",
              "  0.2543351948261261,\n",
              "  0.25008970499038696,\n",
              "  0.24527288973331451,\n",
              "  0.23191991448402405,\n",
              "  0.22820866107940674,\n",
              "  0.22704334557056427,\n",
              "  0.23068450391292572,\n",
              "  0.2254652976989746,\n",
              "  0.2230444848537445,\n",
              "  0.22420084476470947,\n",
              "  0.236838698387146,\n",
              "  0.22531843185424805,\n",
              "  0.25656405091285706,\n",
              "  0.25549060106277466,\n",
              "  0.2360779345035553,\n",
              "  0.2331642061471939,\n",
              "  0.2189951390028,\n",
              "  0.23233942687511444,\n",
              "  0.22642795741558075,\n",
              "  0.237804114818573,\n",
              "  0.23965419828891754,\n",
              "  0.22208580374717712,\n",
              "  0.213993638753891,\n",
              "  0.202289417386055,\n",
              "  0.20624160766601562,\n",
              "  0.19914089143276215,\n",
              "  0.21333344280719757,\n",
              "  0.20727813243865967,\n",
              "  0.20258378982543945,\n",
              "  0.21340687572956085,\n",
              "  0.18952086567878723,\n",
              "  0.19427381455898285,\n",
              "  0.2308206856250763,\n",
              "  0.2027425616979599,\n",
              "  0.1896401047706604,\n",
              "  0.2163001000881195,\n",
              "  0.2150442749261856,\n",
              "  0.18753719329833984],\n",
              " 'val_accuracy': [0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0023809524718672037,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037,\n",
              "  0.0023809524718672037],\n",
              " 'val_loss': [0.7294192910194397,\n",
              "  0.7188943028450012,\n",
              "  0.7353529930114746,\n",
              "  0.7348165512084961,\n",
              "  0.7437567114830017,\n",
              "  0.7496841549873352,\n",
              "  0.7548239827156067,\n",
              "  0.7433646321296692,\n",
              "  0.7624835968017578,\n",
              "  0.7546906471252441,\n",
              "  0.770186185836792,\n",
              "  0.7651349306106567,\n",
              "  0.7698295712471008,\n",
              "  0.77019864320755,\n",
              "  0.7617800235748291,\n",
              "  0.7632856965065002,\n",
              "  0.7690522074699402,\n",
              "  0.7668410539627075,\n",
              "  0.7629159092903137,\n",
              "  0.759503185749054,\n",
              "  0.764714777469635,\n",
              "  0.760491669178009,\n",
              "  0.7641688585281372,\n",
              "  0.770850419998169,\n",
              "  0.7684524059295654,\n",
              "  0.766576886177063,\n",
              "  0.7655069828033447,\n",
              "  0.7558626532554626,\n",
              "  0.7556342482566833,\n",
              "  0.7582522630691528,\n",
              "  0.7577297687530518,\n",
              "  0.7548616528511047,\n",
              "  0.7635162472724915,\n",
              "  0.7600537538528442,\n",
              "  0.7566133141517639,\n",
              "  0.7538774013519287,\n",
              "  0.7550011277198792,\n",
              "  0.7522898316383362,\n",
              "  0.7553061842918396,\n",
              "  0.7472994327545166,\n",
              "  0.7460799217224121,\n",
              "  0.7417812347412109,\n",
              "  0.7451819181442261,\n",
              "  0.7402370572090149,\n",
              "  0.7411362528800964,\n",
              "  0.7395005822181702,\n",
              "  0.7490545511245728,\n",
              "  0.7456259727478027,\n",
              "  0.7482747435569763,\n",
              "  0.7470100522041321,\n",
              "  0.742466926574707,\n",
              "  0.7325607538223267,\n",
              "  0.746191680431366,\n",
              "  0.7436286807060242,\n",
              "  0.7412965297698975,\n",
              "  0.7479056715965271,\n",
              "  0.7445544004440308,\n",
              "  0.748834490776062,\n",
              "  0.746637761592865,\n",
              "  0.7464806437492371,\n",
              "  0.7365361452102661,\n",
              "  0.739852786064148,\n",
              "  0.74106764793396,\n",
              "  0.7454790472984314,\n",
              "  0.7475225329399109,\n",
              "  0.741646409034729,\n",
              "  0.7296820282936096,\n",
              "  0.7434125542640686,\n",
              "  0.748957633972168,\n",
              "  0.7435348033905029,\n",
              "  0.7450255155563354,\n",
              "  0.7492170929908752,\n",
              "  0.7595719695091248,\n",
              "  0.755615234375,\n",
              "  0.7515151500701904,\n",
              "  0.7671628594398499,\n",
              "  0.7608465552330017,\n",
              "  0.770954966545105,\n",
              "  0.757893979549408,\n",
              "  0.7600057721138,\n",
              "  0.7823864221572876,\n",
              "  0.7648200392723083,\n",
              "  0.7568629384040833,\n",
              "  0.779836893081665,\n",
              "  0.7542982697486877,\n",
              "  0.7586384415626526,\n",
              "  0.7564202547073364,\n",
              "  0.7707810997962952,\n",
              "  0.7637165784835815,\n",
              "  0.777935266494751,\n",
              "  0.7722314596176147,\n",
              "  0.7843866944313049,\n",
              "  0.76085364818573,\n",
              "  0.7727257013320923,\n",
              "  0.7674634456634521,\n",
              "  0.7780734896659851,\n",
              "  0.7639538049697876,\n",
              "  0.741954505443573,\n",
              "  0.7538319230079651,\n",
              "  0.7632704377174377,\n",
              "  0.7509930729866028,\n",
              "  0.7764429450035095,\n",
              "  0.7570018172264099,\n",
              "  0.74683678150177,\n",
              "  0.78131502866745,\n",
              "  0.7572468519210815,\n",
              "  0.7332822680473328,\n",
              "  0.7329244613647461,\n",
              "  0.730747640132904,\n",
              "  0.760337769985199,\n",
              "  0.7587149739265442,\n",
              "  0.7456349730491638,\n",
              "  0.7524879574775696,\n",
              "  0.7695068120956421,\n",
              "  0.7593765258789062,\n",
              "  0.7548505663871765,\n",
              "  0.7544171810150146,\n",
              "  0.7446471452713013,\n",
              "  0.760999321937561,\n",
              "  0.7595365047454834,\n",
              "  0.7518256306648254,\n",
              "  0.7489441633224487,\n",
              "  0.7536041140556335,\n",
              "  0.7397183179855347,\n",
              "  0.75896155834198,\n",
              "  0.7667646408081055,\n",
              "  0.7514342665672302,\n",
              "  0.7359069585800171,\n",
              "  0.7332767248153687,\n",
              "  0.7458605170249939,\n",
              "  0.754409670829773,\n",
              "  0.7893909811973572,\n",
              "  0.7684926986694336,\n",
              "  0.7762089967727661,\n",
              "  0.7659212350845337,\n",
              "  0.762687087059021,\n",
              "  0.7827261686325073,\n",
              "  0.7833906412124634,\n",
              "  0.800887942314148,\n",
              "  0.785468339920044,\n",
              "  0.7648796439170837,\n",
              "  0.767797589302063,\n",
              "  0.7821490168571472,\n",
              "  0.7702652812004089,\n",
              "  0.7793958187103271,\n",
              "  0.7828444242477417,\n",
              "  0.7957285642623901,\n",
              "  0.7906312346458435,\n",
              "  0.7869963049888611,\n",
              "  0.8092423677444458,\n",
              "  0.8429226875305176,\n",
              "  0.8119669556617737,\n",
              "  0.8570692539215088,\n",
              "  0.8447255492210388,\n",
              "  0.815737247467041,\n",
              "  0.8260703682899475,\n",
              "  0.8145315051078796,\n",
              "  0.8274697661399841,\n",
              "  0.8033891320228577,\n",
              "  0.8266491889953613,\n",
              "  0.8447186946868896,\n",
              "  0.8409030437469482,\n",
              "  0.8176847100257874,\n",
              "  0.8664717078208923,\n",
              "  0.8914903998374939,\n",
              "  0.833992063999176,\n",
              "  0.8773338794708252,\n",
              "  0.826752245426178,\n",
              "  0.8400265574455261,\n",
              "  0.8315214514732361,\n",
              "  0.8770453333854675,\n",
              "  0.8864182233810425,\n",
              "  0.8797544240951538,\n",
              "  0.861861526966095,\n",
              "  0.8892881870269775,\n",
              "  0.9115036725997925,\n",
              "  0.9037964344024658,\n",
              "  0.9149465560913086,\n",
              "  0.8805522918701172,\n",
              "  0.9254078269004822,\n",
              "  0.9098032116889954,\n",
              "  0.886815071105957,\n",
              "  0.8873704671859741,\n",
              "  0.9501562118530273,\n",
              "  1.0309752225875854,\n",
              "  1.0507220029830933,\n",
              "  1.0162341594696045,\n",
              "  1.0038015842437744,\n",
              "  1.0143053531646729,\n",
              "  1.019544243812561,\n",
              "  1.0557172298431396,\n",
              "  1.0721282958984375,\n",
              "  0.992760419845581,\n",
              "  1.1316418647766113,\n",
              "  1.0608073472976685,\n",
              "  1.1365448236465454,\n",
              "  1.105860948562622,\n",
              "  1.1270473003387451,\n",
              "  1.0267398357391357,\n",
              "  1.1355431079864502,\n",
              "  1.127426028251648,\n",
              "  1.1554629802703857,\n",
              "  1.1462496519088745,\n",
              "  1.1716187000274658,\n",
              "  1.1347050666809082,\n",
              "  1.0961885452270508,\n",
              "  1.162843108177185,\n",
              "  1.16377592086792,\n",
              "  1.2062100172042847,\n",
              "  1.1472326517105103,\n",
              "  1.2405104637145996,\n",
              "  1.2302558422088623,\n",
              "  1.200802206993103,\n",
              "  1.233885407447815,\n",
              "  1.3198226690292358,\n",
              "  1.2354705333709717,\n",
              "  1.3670207262039185,\n",
              "  1.2833411693572998,\n",
              "  1.2920957803726196,\n",
              "  1.3248893022537231,\n",
              "  1.3817230463027954,\n",
              "  1.3857131004333496,\n",
              "  1.364567518234253,\n",
              "  1.4215896129608154,\n",
              "  1.3996999263763428,\n",
              "  1.39730703830719,\n",
              "  1.4283586740493774,\n",
              "  1.409091591835022,\n",
              "  1.4439294338226318,\n",
              "  1.4301371574401855,\n",
              "  1.4782859086990356,\n",
              "  1.4097189903259277,\n",
              "  1.5036603212356567,\n",
              "  1.5522202253341675,\n",
              "  1.5352513790130615,\n",
              "  1.5719705820083618,\n",
              "  1.6371790170669556,\n",
              "  1.640971302986145,\n",
              "  1.6842254400253296,\n",
              "  1.7217319011688232,\n",
              "  1.693352222442627,\n",
              "  1.7958705425262451,\n",
              "  1.7713065147399902,\n",
              "  1.862250804901123,\n",
              "  1.8987501859664917,\n",
              "  1.8374249935150146,\n",
              "  1.866430401802063,\n",
              "  2.011456251144409,\n",
              "  2.0866568088531494,\n",
              "  1.88187575340271,\n",
              "  2.022904634475708,\n",
              "  2.1681458950042725,\n",
              "  2.138188600540161,\n",
              "  2.280027389526367,\n",
              "  2.13913631439209,\n",
              "  2.356570243835449,\n",
              "  2.2873334884643555,\n",
              "  2.3436927795410156,\n",
              "  2.3306782245635986,\n",
              "  2.4149115085601807,\n",
              "  2.4263556003570557,\n",
              "  2.530078649520874,\n",
              "  2.494370222091675,\n",
              "  2.5892560482025146,\n",
              "  2.6709647178649902,\n",
              "  2.804224729537964,\n",
              "  2.7171263694763184,\n",
              "  2.7297616004943848,\n",
              "  2.8340890407562256,\n",
              "  2.9329357147216797,\n",
              "  3.0926060676574707,\n",
              "  3.0883991718292236,\n",
              "  3.2353432178497314,\n",
              "  3.098590612411499,\n",
              "  3.2954909801483154,\n",
              "  3.540266752243042,\n",
              "  3.406987190246582,\n",
              "  3.5364339351654053,\n",
              "  3.340815544128418,\n",
              "  3.5060055255889893,\n",
              "  3.48244309425354,\n",
              "  3.452590227127075,\n",
              "  3.6836295127868652,\n",
              "  3.6876163482666016,\n",
              "  3.6666605472564697,\n",
              "  3.668226480484009,\n",
              "  3.704526424407959,\n",
              "  3.72698712348938,\n",
              "  3.796818256378174,\n",
              "  3.833716630935669,\n",
              "  3.876201868057251,\n",
              "  3.9458940029144287,\n",
              "  3.884798526763916,\n",
              "  3.9349448680877686,\n",
              "  3.986274003982544,\n",
              "  4.065794944763184,\n",
              "  4.110856533050537,\n",
              "  4.173549652099609,\n",
              "  4.191433429718018,\n",
              "  4.262320518493652]}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QjkAR4aheUX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8820ca71-8618-47c4-a4b5-99716d3afb8f"
      },
      "source": [
        "# Plot accuracy per iteration\n",
        "plt.plot(r.history['accuracy'], label='accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='val_accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JsiSsoeGthC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}